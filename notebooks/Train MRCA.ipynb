{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff950d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "from dataloaders import data_set,data_dict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b2ead2",
   "metadata": {},
   "source": [
    "# MotionSense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05954e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()    \n",
    "args.root_path = r\"D:\\TECO\\Paper\\datasets\\Motion_Sense_Dataset\\data\"\n",
    "args.freq_save_path = r\"D:\\TECO\\Paper\\Final_version\\Freq_data\"\n",
    "args.data_name = \"motionsense\"\n",
    "\n",
    "args.difference = True \n",
    "\n",
    "args.sampling_freq =   50   # -----------\n",
    "args.windowsize = int(2.56* args.sampling_freq) # -----------\n",
    "args.displacement =  int(0.5 * args.windowsize)  # -----------\n",
    "args.weighted  = False\n",
    "args.drop_long = False\n",
    "args.datanorm_type = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "args.wavename = \"morl\"\n",
    "\n",
    "# input information\n",
    "args.c_in      =  24 # it depends on the dataset # -----------\n",
    "args.input_length  =  args.windowsize   # it depends on the dataset # -----------\n",
    "args.num_classes  =  6 # -----------\n",
    "\n",
    "args.batch_size = 64\n",
    "args.shuffle = True\n",
    "args.drop_last = False\n",
    "args.train_vali_quote = 0.95\n",
    "\n",
    "\n",
    "\n",
    "args.exp_mode = \"Given\"\n",
    "args.model_type = \"time\"\n",
    "args.cls_token = True\n",
    "\n",
    "if args.model_type  in [\"time\",\"freq\",\"cross\"]:\n",
    "    args.light_weight      = False\n",
    "    # embedding \n",
    "    args.spectrogram      = True if args.model_type in [\"freq\",\"cross\"] else False\n",
    "    args.wavelet        = 'morl'\n",
    "\n",
    "    args.token_d_model     =  48\n",
    "    args.token_kernel_size   =  3\n",
    "    args.token_stride      =  1\n",
    "    args.token_conv_bias    =  True\n",
    "    args.token_activation    =  \"hardswish\"\n",
    "    args.token_norm       =  \"layer\"\n",
    "    args.token_n_layers     =  2\n",
    "    args.token_in_planes    =  48\n",
    "    args.token_max_pool     =  False\n",
    "    args.token_pool_kernel_size =  3\n",
    "    args.token_pool_stride    =  1\n",
    "    args.token_pool_pad      =  1\n",
    "    args.positional_embedding   = \"learnable\"    #None , \"learnable\" , \"sinus\"\n",
    "    args.input_embedding_dropout = 0.1\n",
    "\n",
    "    # Encoder\n",
    "    args.bias          = False\n",
    "    args.padding_mode      = \"replicate\"\n",
    "\n",
    "    args.single_depth        = 2\n",
    "    \n",
    "    # only model type == cross\n",
    "    args.cross_depth    = 1\n",
    "    args.t_depth        = 2\n",
    "    args.cross_atten_depth = 1\n",
    "    \n",
    "    args.distil         = False\n",
    "\n",
    "    #args.mask_flag                  = False\n",
    "    args.attention_layer_types = \"Full\" #[\"Full\",\"LocalSymmetry\",\"LocLogSymmetry\"]\n",
    "    args.attention_dropout   = 0.1   # attention map 也就是score的drop\n",
    "    args.output_attention    = True\n",
    "\n",
    "    args.n_heads        = 6\n",
    "    args.d_keys         = None\n",
    "    args.d_values        = None\n",
    "    args.causal_kernel_size   = 3\n",
    "    args.value_kernel_size   = 3\n",
    "    args.projection_dropout   = 0.1\n",
    "\n",
    "    args.feedforward_dim    = None\n",
    "    args.feedforward_dropout  = 0.1\n",
    "    args.feedforward_activation = \"hardswish\"\n",
    "    args.feedforward_norm_type = \"layer\"\n",
    "    args.forward_kernel_size  = 3\n",
    "    args.conv_activation    = \"hardswish\"\n",
    "    args.conv_norm       = \"layer\"\n",
    "else:\n",
    "    args.token_d_model     = 128\n",
    "    args.positional_embedding  = \"learnable\" # \"learnable\",\"fixed\"\n",
    "    args.input_embedding_dropout = 0.1\n",
    "    args.norm_type       = \"b\" # \"LayerNorm\" ,\"Batch\"\n",
    "    args.n_heads        = 8\n",
    "    args.dim_feedforward    = args.token_d_model*4\n",
    "    args.attn_dropout     = 0.1\n",
    "    args.activation      = \"relu\" # \"relu\", \"gelu\"\n",
    "    args.num_layers      = 4\n",
    "\n",
    "# training setting \n",
    "args.train_epochs       = 200\n",
    "\n",
    "args.learning_rate      = 0.001  \n",
    "args.learning_rate_patience  = 7\n",
    "args.learning_rate_factor   = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience    = 21\n",
    "\n",
    "args.use_gpu         = True if torch.cuda.is_available() else False\n",
    "args.gpu           = 0\n",
    "args.use_multi_gpu      = False\n",
    "\n",
    "args.optimizer        = \"Adam\"\n",
    "args.criterion        = \"CrossEntropy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21461e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "beginn to build model\n",
      "build embedding Done\n",
      "build encoder Done\n",
      "build transformer Done\n",
      "build prediction Done\n",
      "Build the conv_TS model!\n",
      "Parameter : 128166\n"
     ]
    }
   ],
   "source": [
    "exp = Exp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f834002b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----------------------- load all the data -------------------\n",
      "----------------------- Get the Sliding Window -------------------\n",
      "The orginal class weights are :  [1.8391 1.5276 0.6876 0.7612 0.6805 1.7728]\n",
      "================ Given Mode ====================\n",
      "================ 1 CV ======================\n",
      "================ Build the model ================ \n",
      "beginn to build model\n",
      "build embedding Done\n",
      "build encoder Done\n",
      "build transformer Done\n",
      "build prediction Done\n",
      "Build the conv_TS model!\n",
      "================ the 1 th CV Experiment ================ \n",
      "After update the train test split , the class weight : [1.6957 1.4189 0.7615 0.7959 0.6407 1.7384]\n",
      "Train data number :  15750\n",
      "The number of classes is :  6\n",
      "The input_length  is :  128\n",
      "The channel_in is :  24\n",
      "Test data number :  4960\n",
      "Epoch: 1 cost time: 26.449021339416504\n",
      "Epoch: 1, Steps: 247 | Train Loss: 0.3029816  Vali Loss: 0.1958630 Vali Accuracy: 0.9502016  Vali weighted F1: 0.9547321  Vali macro F1 0.9285489 \n",
      "Validation loss decreased (inf --> 0.195863).  Saving model ...\n",
      "Epoch: 2 cost time: 25.12393856048584\n",
      "Epoch: 2, Steps: 247 | Train Loss: 0.0971702  Vali Loss: 0.2083724 Vali Accuracy: 0.9534274  Vali weighted F1: 0.9549450  Vali macro F1 0.9298323 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 3 cost time: 25.445433616638184\n",
      "Epoch: 3, Steps: 247 | Train Loss: 0.0727174  Vali Loss: 0.2320375 Vali Accuracy: 0.9520161  Vali weighted F1: 0.9534513  Vali macro F1 0.9299108 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 4 cost time: 25.033531188964844\n",
      "Epoch: 4, Steps: 247 | Train Loss: 0.0655961  Vali Loss: 0.2024151 Vali Accuracy: 0.9673387  Vali weighted F1: 0.9686114  Vali macro F1 0.9488701 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 5 cost time: 25.075653791427612\n",
      "Epoch: 5, Steps: 247 | Train Loss: 0.0583858  Vali Loss: 0.2155037 Vali Accuracy: 0.9663306  Vali weighted F1: 0.9681428  Vali macro F1 0.9459402 \n",
      "EarlyStopping counter: 4 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 6 cost time: 25.083553314208984\n",
      "Epoch: 6, Steps: 247 | Train Loss: 0.0422671  Vali Loss: 0.1650592 Vali Accuracy: 0.9709677  Vali weighted F1: 0.9723576  Vali macro F1 0.9529096 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.195863 --> 0.165059).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 7 cost time: 25.069388389587402\n",
      "Epoch: 7, Steps: 247 | Train Loss: 0.0483084  Vali Loss: 0.2001282 Vali Accuracy: 0.9697581  Vali weighted F1: 0.9712660  Vali macro F1 0.9512893 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 8 cost time: 25.06721520423889\n",
      "Epoch: 8, Steps: 247 | Train Loss: 0.0380317  Vali Loss: 0.2110177 Vali Accuracy: 0.9669355  Vali weighted F1: 0.9686673  Vali macro F1 0.9481629 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 9 cost time: 25.067476511001587\n",
      "Epoch: 9, Steps: 247 | Train Loss: 0.0378074  Vali Loss: 0.2015514 Vali Accuracy: 0.9614919  Vali weighted F1: 0.9633873  Vali macro F1 0.9376619 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 10 cost time: 25.064565420150757\n",
      "Epoch: 10, Steps: 247 | Train Loss: 0.0319278  Vali Loss: 0.1708395 Vali Accuracy: 0.9729839  Vali weighted F1: 0.9736565  Vali macro F1 0.9571147 \n",
      "EarlyStopping counter: 4 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 11 cost time: 25.067814350128174\n",
      "Epoch: 11, Steps: 247 | Train Loss: 0.0314807  Vali Loss: 0.2225577 Vali Accuracy: 0.9627016  Vali weighted F1: 0.9655570  Vali macro F1 0.9409850 \n",
      "EarlyStopping counter: 5 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 12 cost time: 25.070500135421753\n",
      "Epoch: 12, Steps: 247 | Train Loss: 0.0352076  Vali Loss: 0.2242335 Vali Accuracy: 0.9673387  Vali weighted F1: 0.9693544  Vali macro F1 0.9444474 \n",
      "EarlyStopping counter: 6 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 13 cost time: 25.067062616348267\n",
      "Epoch: 13, Steps: 247 | Train Loss: 0.0285781  Vali Loss: 0.2015856 Vali Accuracy: 0.9699597  Vali weighted F1: 0.9715736  Vali macro F1 0.9512003 \n",
      "EarlyStopping counter: 7 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 14 cost time: 25.066932439804077\n",
      "Epoch: 14, Steps: 247 | Train Loss: 0.0157862  Vali Loss: 0.1945332 Vali Accuracy: 0.9727823  Vali weighted F1: 0.9743204  Vali macro F1 0.9553182 \n",
      "EarlyStopping counter: 8 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 15 cost time: 25.07534432411194\n",
      "Epoch: 15, Steps: 247 | Train Loss: 0.0081603  Vali Loss: 0.1994905 Vali Accuracy: 0.9721774  Vali weighted F1: 0.9737478  Vali macro F1 0.9539997 \n",
      "EarlyStopping counter: 9 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 16 cost time: 25.056093454360962\n",
      "Epoch: 16, Steps: 247 | Train Loss: 0.0059714  Vali Loss: 0.2048164 Vali Accuracy: 0.9717742  Vali weighted F1: 0.9733762  Vali macro F1 0.9533840 \n",
      "EarlyStopping counter: 10 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 17 cost time: 25.05578064918518\n",
      "Epoch: 17, Steps: 247 | Train Loss: 0.0048794  Vali Loss: 0.2024448 Vali Accuracy: 0.9727823  Vali weighted F1: 0.9743506  Vali macro F1 0.9554803 \n",
      "EarlyStopping counter: 11 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 18 cost time: 25.082740306854248\n",
      "Epoch: 18, Steps: 247 | Train Loss: 0.0045952  Vali Loss: 0.2032459 Vali Accuracy: 0.9735887  Vali weighted F1: 0.9750317  Vali macro F1 0.9569906 \n",
      "EarlyStopping counter: 12 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 19 cost time: 25.066917896270752\n",
      "Epoch: 19, Steps: 247 | Train Loss: 0.0032561  Vali Loss: 0.2066938 Vali Accuracy: 0.9729839  Vali weighted F1: 0.9745387  Vali macro F1 0.9564369 \n",
      "EarlyStopping counter: 13 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 20 cost time: 25.074342489242554\n",
      "Epoch: 20, Steps: 247 | Train Loss: 0.0031955  Vali Loss: 0.2112488 Vali Accuracy: 0.9719758  Vali weighted F1: 0.9735295  Vali macro F1 0.9539265 \n",
      "EarlyStopping counter: 14 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 21 cost time: 25.07469654083252\n",
      "Epoch: 21, Steps: 247 | Train Loss: 0.0019236  Vali Loss: 0.2116296 Vali Accuracy: 0.9717742  Vali weighted F1: 0.9733800  Vali macro F1 0.9534165 \n",
      "EarlyStopping counter: 15 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 22 cost time: 25.074114322662354\n",
      "Epoch: 22, Steps: 247 | Train Loss: 0.0016131  Vali Loss: 0.2107150 Vali Accuracy: 0.9721774  Vali weighted F1: 0.9737357  Vali macro F1 0.9542301 \n",
      "EarlyStopping counter: 16 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 23 cost time: 25.065810441970825\n",
      "Epoch: 23, Steps: 247 | Train Loss: 0.0019290  Vali Loss: 0.2113831 Vali Accuracy: 0.9721774  Vali weighted F1: 0.9737566  Vali macro F1 0.9542894 \n",
      "EarlyStopping counter: 17 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 24 cost time: 25.052759408950806\n",
      "Epoch: 24, Steps: 247 | Train Loss: 0.0016029  Vali Loss: 0.2113865 Vali Accuracy: 0.9721774  Vali weighted F1: 0.9737566  Vali macro F1 0.9542894 \n",
      "EarlyStopping counter: 18 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 25 cost time: 25.05624294281006\n",
      "Epoch: 25, Steps: 247 | Train Loss: 0.0021418  Vali Loss: 0.2104213 Vali Accuracy: 0.9723790  Vali weighted F1: 0.9739422  Vali macro F1 0.9546420 \n",
      "EarlyStopping counter: 19 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 26 cost time: 25.06864285469055\n",
      "Epoch: 26, Steps: 247 | Train Loss: 0.0015322  Vali Loss: 0.2100270 Vali Accuracy: 0.9725806  Vali weighted F1: 0.9741412  Vali macro F1 0.9552382 \n",
      "EarlyStopping counter: 20 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 27 cost time: 25.07965326309204\n",
      "Epoch: 27, Steps: 247 | Train Loss: 0.0016377  Vali Loss: 0.2107405 Vali Accuracy: 0.9723790  Vali weighted F1: 0.9739843  Vali macro F1 0.9547612 \n",
      "EarlyStopping counter: 21 out of 21\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "exp.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd077a1a",
   "metadata": {},
   "source": [
    "# PAMAP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb54e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()    \n",
    "args.root_path =  r\"D:\\TECO\\Paper\\datasets\\PAMAP2_Dataset\\Protocol\"  # -----------\n",
    "args.freq_save_path = r\"D:\\TECO\\Paper\\Final_version\\Freq_data\"\n",
    "args.data_name = \"pamap2\"  # -----------\n",
    "\n",
    "args.difference = True \n",
    "\n",
    "args.sampling_freq =   int(100/3)   # -----------\n",
    "args.windowsize = int(5.12 * args.sampling_freq) # -----------\n",
    "args.displacement =  int(0.5 * args.windowsize)  # -----------\n",
    "args.weighted  = False\n",
    "args.drop_long = False\n",
    "args.datanorm_type = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "args.wavename = \"morl\"\n",
    "\n",
    "# input information\n",
    "args.c_in      =  18*2 # it depends on the dataset # -----------\n",
    "args.input_length  =  args.windowsize\n",
    "args.num_classes  =  12 # -----------\n",
    "\n",
    "args.batch_size = 64\n",
    "args.shuffle = True\n",
    "args.drop_last = False\n",
    "args.train_vali_quote = 0.95\n",
    "\n",
    "\n",
    "\n",
    "args.exp_mode = \"Given\"\n",
    "args.model_type = \"time\"\n",
    "args.cls_token = True\n",
    "\n",
    "if args.model_type  in [\"time\",\"freq\",\"cross\"]:\n",
    "    args.light_weight      = False\n",
    "    # embedding \n",
    "    args.spectrogram      = True if args.model_type in [\"freq\",\"cross\"] else False\n",
    "    args.wavelet        = 'morl'\n",
    "\n",
    "    args.token_d_model     =  48\n",
    "    args.token_kernel_size   =  3\n",
    "    args.token_stride      =  1\n",
    "    args.token_conv_bias    =  True\n",
    "    args.token_activation    =  \"hardswish\"\n",
    "    args.token_norm       =  \"layer\"\n",
    "    args.token_n_layers     =  2\n",
    "    args.token_in_planes    =  48\n",
    "    args.token_max_pool     =  False\n",
    "    args.token_pool_kernel_size =  3\n",
    "    args.token_pool_stride    =  1\n",
    "    args.token_pool_pad      =  1\n",
    "    args.positional_embedding   = \"learnable\"    #None , \"learnable\" , \"sinus\"\n",
    "    args.input_embedding_dropout = 0.1\n",
    "\n",
    "    # Encoder\n",
    "    args.bias          = False\n",
    "    args.padding_mode      = \"replicate\"\n",
    "\n",
    "    args.single_depth        = 2\n",
    "    \n",
    "    # only model type == cross\n",
    "    args.cross_depth    = 1\n",
    "    args.t_depth        = 2\n",
    "    args.cross_atten_depth = 1\n",
    "    \n",
    "    args.distil         = False\n",
    "\n",
    "    #args.mask_flag                  = False\n",
    "    args.attention_layer_types = \"Full\" #[\"Full\",\"LocalSymmetry\",\"LocLogSymmetry\"]\n",
    "    args.attention_dropout   = 0.1   # attention map 也就是score的drop\n",
    "    args.output_attention    = True\n",
    "\n",
    "    args.n_heads        = 6\n",
    "    args.d_keys         = None\n",
    "    args.d_values        = None\n",
    "    args.causal_kernel_size   = 3\n",
    "    args.value_kernel_size   = 3\n",
    "    args.projection_dropout   = 0.1\n",
    "\n",
    "    args.feedforward_dim    = None\n",
    "    args.feedforward_dropout  = 0.1\n",
    "    args.feedforward_activation = \"hardswish\"\n",
    "    args.feedforward_norm_type = \"layer\"\n",
    "    args.forward_kernel_size  = 3\n",
    "    args.conv_activation    = \"hardswish\"\n",
    "    args.conv_norm       = \"layer\"\n",
    "else:\n",
    "    args.token_d_model     = 128\n",
    "    args.positional_embedding  = \"learnable\" # \"learnable\",\"fixed\"\n",
    "    args.input_embedding_dropout = 0.1\n",
    "    args.norm_type       = \"b\" # \"LayerNorm\" ,\"Batch\"\n",
    "    args.n_heads        = 8\n",
    "    args.dim_feedforward    = args.token_d_model*4\n",
    "    args.attn_dropout     = 0.1\n",
    "    args.activation      = \"relu\" # \"relu\", \"gelu\"\n",
    "    args.num_layers      = 4\n",
    "\n",
    "# training setting \n",
    "args.train_epochs       = 200\n",
    "\n",
    "args.learning_rate      = 0.001  \n",
    "args.learning_rate_patience  = 7\n",
    "args.learning_rate_factor   = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience    = 21\n",
    "\n",
    "args.use_gpu         = True if torch.cuda.is_available() else False\n",
    "args.gpu           = 0\n",
    "args.use_multi_gpu      = False\n",
    "\n",
    "args.optimizer        = \"Adam\"\n",
    "args.criterion        = \"CrossEntropy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80fa8c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "beginn to build model\n",
      "build embedding Done\n",
      "build encoder Done\n",
      "build transformer Done\n",
      "build prediction Done\n",
      "Build the conv_TS model!\n",
      "Parameter : 132108\n"
     ]
    }
   ],
   "source": [
    "exp = Exp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66a6dd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----------------------- load all the data -------------------\n",
      "----------------------- Get the Sliding Window -------------------\n",
      "The orginal class weights are :  [0.8381 0.8706 0.8483 0.6717 1.6564 0.9774 0.8552 1.4272 1.6098 0.9189\n",
      " 0.6725 3.3659]\n",
      "================ Given Mode ====================\n",
      "================ 1 CV ======================\n",
      "================ Build the model ================ \n",
      "beginn to build model\n",
      "build embedding Done\n",
      "build encoder Done\n",
      "build transformer Done\n",
      "build prediction Done\n",
      "Build the conv_TS model!\n",
      "================ the 1 th CV Experiment ================ \n",
      "After update the train test split , the class weight : [0.8295 0.8653 0.8526 0.6561 1.9081 0.9719 0.8784 1.3781 1.5738 0.9139\n",
      " 0.689  2.9101]\n",
      "Train data number :  6251\n",
      "The number of classes is :  12\n",
      "The input_length  is :  168\n",
      "The channel_in is :  36\n",
      "Test data number :  972\n",
      "Epoch: 1 cost time: 12.717317819595337\n",
      "Epoch: 1, Steps: 98 | Train Loss: 0.7989782  Vali Loss: 0.4299120 Vali Accuracy: 0.8940329  Vali weighted F1: 0.8919372  Vali macro F1 0.8852845 \n",
      "Validation loss decreased (inf --> 0.429912).  Saving model ...\n",
      "Epoch: 2 cost time: 12.672865152359009\n",
      "Epoch: 2, Steps: 98 | Train Loss: 0.2824374  Vali Loss: 0.3714278 Vali Accuracy: 0.9125514  Vali weighted F1: 0.9089495  Vali macro F1 0.9062603 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.429912 --> 0.371428).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 12.716858625411987\n",
      "Epoch: 3, Steps: 98 | Train Loss: 0.1997996  Vali Loss: 0.4990854 Vali Accuracy: 0.8611111  Vali weighted F1: 0.8602743  Vali macro F1 0.8645728 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 4 cost time: 12.763870477676392\n",
      "Epoch: 4, Steps: 98 | Train Loss: 0.1615191  Vali Loss: 0.3443747 Vali Accuracy: 0.9002058  Vali weighted F1: 0.9028705  Vali macro F1 0.8965870 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.371428 --> 0.344375).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 12.760461807250977\n",
      "Epoch: 5, Steps: 98 | Train Loss: 0.1321986  Vali Loss: 0.4579892 Vali Accuracy: 0.8652263  Vali weighted F1: 0.8664026  Vali macro F1 0.8707116 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 6 cost time: 12.77137041091919\n",
      "Epoch: 6, Steps: 98 | Train Loss: 0.1315521  Vali Loss: 0.4100162 Vali Accuracy: 0.8981481  Vali weighted F1: 0.8983097  Vali macro F1 0.8993660 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 7 cost time: 12.770813941955566\n",
      "Epoch: 7, Steps: 98 | Train Loss: 0.1069969  Vali Loss: 0.3774836 Vali Accuracy: 0.8981481  Vali weighted F1: 0.9020689  Vali macro F1 0.8268658 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 8 cost time: 12.772894859313965\n",
      "Epoch: 8, Steps: 98 | Train Loss: 0.1012409  Vali Loss: 0.3314785 Vali Accuracy: 0.9125514  Vali weighted F1: 0.9131578  Vali macro F1 0.9120032 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.344375 --> 0.331479).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 12.773879766464233\n",
      "Epoch: 9, Steps: 98 | Train Loss: 0.0810410  Vali Loss: 0.4643019 Vali Accuracy: 0.8683128  Vali weighted F1: 0.8671421  Vali macro F1 0.8736534 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 10 cost time: 12.772879123687744\n",
      "Epoch: 10, Steps: 98 | Train Loss: 0.1085597  Vali Loss: 0.4020341 Vali Accuracy: 0.9115226  Vali weighted F1: 0.9121076  Vali macro F1 0.9145913 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 11 cost time: 12.776456117630005\n",
      "Epoch: 11, Steps: 98 | Train Loss: 0.0808060  Vali Loss: 0.3737621 Vali Accuracy: 0.9135802  Vali weighted F1: 0.9165967  Vali macro F1 0.8380382 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 12 cost time: 12.769870042800903\n",
      "Epoch: 12, Steps: 98 | Train Loss: 0.0625791  Vali Loss: 0.4945843 Vali Accuracy: 0.8847737  Vali weighted F1: 0.8831685  Vali macro F1 0.8101668 \n",
      "EarlyStopping counter: 4 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 13 cost time: 12.775879859924316\n",
      "Epoch: 13, Steps: 98 | Train Loss: 0.0603506  Vali Loss: 0.4883331 Vali Accuracy: 0.8950617  Vali weighted F1: 0.8931641  Vali macro F1 0.8264655 \n",
      "EarlyStopping counter: 5 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 14 cost time: 12.767817735671997\n",
      "Epoch: 14, Steps: 98 | Train Loss: 0.0755603  Vali Loss: 0.4913230 Vali Accuracy: 0.8847737  Vali weighted F1: 0.8855560  Vali macro F1 0.8175112 \n",
      "EarlyStopping counter: 6 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 15 cost time: 12.771755695343018\n",
      "Epoch: 15, Steps: 98 | Train Loss: 0.0784080  Vali Loss: 0.4847307 Vali Accuracy: 0.8888889  Vali weighted F1: 0.8911659  Vali macro F1 0.8170536 \n",
      "EarlyStopping counter: 7 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 16 cost time: 12.768603801727295\n",
      "Epoch: 16, Steps: 98 | Train Loss: 0.0434676  Vali Loss: 0.4043343 Vali Accuracy: 0.9063786  Vali weighted F1: 0.9068427  Vali macro F1 0.8326709 \n",
      "EarlyStopping counter: 8 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 17 cost time: 12.770857095718384\n",
      "Epoch: 17, Steps: 98 | Train Loss: 0.0314296  Vali Loss: 0.4093368 Vali Accuracy: 0.9053498  Vali weighted F1: 0.9060255  Vali macro F1 0.8312291 \n",
      "EarlyStopping counter: 9 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 18 cost time: 12.813894987106323\n",
      "Epoch: 18, Steps: 98 | Train Loss: 0.0262013  Vali Loss: 0.4178011 Vali Accuracy: 0.9022634  Vali weighted F1: 0.9026521  Vali macro F1 0.8289345 \n",
      "EarlyStopping counter: 10 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 19 cost time: 12.853461265563965\n",
      "Epoch: 19, Steps: 98 | Train Loss: 0.0241270  Vali Loss: 0.3891439 Vali Accuracy: 0.9094650  Vali weighted F1: 0.9099290  Vali macro F1 0.8342847 \n",
      "EarlyStopping counter: 11 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 20 cost time: 12.851791143417358\n",
      "Epoch: 20, Steps: 98 | Train Loss: 0.0223860  Vali Loss: 0.4114773 Vali Accuracy: 0.9074074  Vali weighted F1: 0.9088902  Vali macro F1 0.8337330 \n",
      "EarlyStopping counter: 12 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 21 cost time: 12.853907823562622\n",
      "Epoch: 21, Steps: 98 | Train Loss: 0.0222503  Vali Loss: 0.4132559 Vali Accuracy: 0.9074074  Vali weighted F1: 0.9078224  Vali macro F1 0.8330403 \n",
      "EarlyStopping counter: 13 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 22 cost time: 12.857906341552734\n",
      "Epoch: 22, Steps: 98 | Train Loss: 0.0199997  Vali Loss: 0.4208640 Vali Accuracy: 0.9094650  Vali weighted F1: 0.9095603  Vali macro F1 0.8340315 \n",
      "EarlyStopping counter: 14 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 23 cost time: 12.853938102722168\n",
      "Epoch: 23, Steps: 98 | Train Loss: 0.0187240  Vali Loss: 0.4206443 Vali Accuracy: 0.9094650  Vali weighted F1: 0.9094803  Vali macro F1 0.8339803 \n",
      "EarlyStopping counter: 15 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 24 cost time: 12.861660242080688\n",
      "Epoch: 24, Steps: 98 | Train Loss: 0.0181896  Vali Loss: 0.4199698 Vali Accuracy: 0.9115226  Vali weighted F1: 0.9118123  Vali macro F1 0.8363561 \n",
      "EarlyStopping counter: 16 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 25 cost time: 12.85178542137146\n",
      "Epoch: 25, Steps: 98 | Train Loss: 0.0177880  Vali Loss: 0.4184939 Vali Accuracy: 0.9104938  Vali weighted F1: 0.9108540  Vali macro F1 0.8358465 \n",
      "EarlyStopping counter: 17 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 26 cost time: 12.856196403503418\n",
      "Epoch: 26, Steps: 98 | Train Loss: 0.0191736  Vali Loss: 0.4215061 Vali Accuracy: 0.9094650  Vali weighted F1: 0.9099015  Vali macro F1 0.8349621 \n",
      "EarlyStopping counter: 18 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 27 cost time: 12.855399370193481\n",
      "Epoch: 27, Steps: 98 | Train Loss: 0.0190990  Vali Loss: 0.4190347 Vali Accuracy: 0.9115226  Vali weighted F1: 0.9119755  Vali macro F1 0.8366785 \n",
      "EarlyStopping counter: 19 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 28 cost time: 12.853891372680664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Steps: 98 | Train Loss: 0.0178118  Vali Loss: 0.4186196 Vali Accuracy: 0.9084362  Vali weighted F1: 0.9087915  Vali macro F1 0.8341552 \n",
      "EarlyStopping counter: 20 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 29 cost time: 12.853816270828247\n",
      "Epoch: 29, Steps: 98 | Train Loss: 0.0175939  Vali Loss: 0.4184165 Vali Accuracy: 0.9094650  Vali weighted F1: 0.9097436  Vali macro F1 0.8350391 \n",
      "EarlyStopping counter: 21 out of 21\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "exp.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932d6d40",
   "metadata": {},
   "source": [
    "# UCI HAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb2304ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()    \n",
    "args.root_path =  r\"D:\\TECO\\Paper\\datasets\\UCI HAR Dataset\"\n",
    "args.freq_save_path = r\"D:\\TECO\\Paper\\Final_version\\Freq_data\"\n",
    "args.data_name = \"ucihar\"  # -----------\n",
    "\n",
    "args.difference = True \n",
    "\n",
    "args.sampling_freq =   50   # -----------\n",
    "args.windowsize = int(2.56 * args.sampling_freq) # -----------\n",
    "args.displacement =  int(1 * args.windowsize)  # -----------\n",
    "args.weighted  = False\n",
    "args.drop_long = False\n",
    "args.datanorm_type = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "args.wavename = \"morl\"\n",
    "\n",
    "# input information\n",
    "args.c_in      =  18 # it depends on the dataset # -----------\n",
    "args.input_length  =  args.windowsize\n",
    "args.num_classes  =  6 # -----------\n",
    "\n",
    "args.batch_size = 64\n",
    "args.shuffle = True\n",
    "args.drop_last = False\n",
    "args.train_vali_quote = 0.95\n",
    "\n",
    "\n",
    "\n",
    "args.exp_mode = \"Given\"\n",
    "args.model_type = \"time\"\n",
    "args.cls_token = True\n",
    "\n",
    "if args.model_type  in [\"time\",\"freq\",\"cross\"]:\n",
    "    args.light_weight      = False\n",
    "    # embedding \n",
    "    args.spectrogram      = True if args.model_type in [\"freq\",\"cross\"] else False\n",
    "    args.wavelet        = 'morl'\n",
    "\n",
    "    args.token_d_model     =  48\n",
    "    args.token_kernel_size   =  3\n",
    "    args.token_stride      =  1\n",
    "    args.token_conv_bias    =  True\n",
    "    args.token_activation    =  \"hardswish\"\n",
    "    args.token_norm       =  \"layer\"\n",
    "    args.token_n_layers     =  2\n",
    "    args.token_in_planes    =  48\n",
    "    args.token_max_pool     =  False\n",
    "    args.token_pool_kernel_size =  3\n",
    "    args.token_pool_stride    =  1\n",
    "    args.token_pool_pad      =  1\n",
    "    args.positional_embedding   = \"learnable\"    #None , \"learnable\" , \"sinus\"\n",
    "    args.input_embedding_dropout = 0.1\n",
    "\n",
    "    # Encoder\n",
    "    args.bias          = False\n",
    "    args.padding_mode      = \"replicate\"\n",
    "\n",
    "    args.single_depth        = 2\n",
    "    \n",
    "    # only model type == cross\n",
    "    args.cross_depth    = 1\n",
    "    args.t_depth        = 2\n",
    "    args.cross_atten_depth = 1\n",
    "    \n",
    "    args.distil         = False\n",
    "\n",
    "    #args.mask_flag                  = False\n",
    "    args.attention_layer_types = \"Full\" #[\"Full\",\"LocalSymmetry\",\"LocLogSymmetry\"]\n",
    "    args.attention_dropout   = 0.1   # attention map 也就是score的drop\n",
    "    args.output_attention    = True\n",
    "\n",
    "    args.n_heads        = 6\n",
    "    args.d_keys         = None\n",
    "    args.d_values        = None\n",
    "    args.causal_kernel_size   = 3\n",
    "    args.value_kernel_size   = 3\n",
    "    args.projection_dropout   = 0.1\n",
    "\n",
    "    args.feedforward_dim    = None\n",
    "    args.feedforward_dropout  = 0.1\n",
    "    args.feedforward_activation = \"hardswish\"\n",
    "    args.feedforward_norm_type = \"layer\"\n",
    "    args.forward_kernel_size  = 3\n",
    "    args.conv_activation    = \"hardswish\"\n",
    "    args.conv_norm       = \"layer\"\n",
    "else:\n",
    "    args.token_d_model     = 128\n",
    "    args.positional_embedding  = \"learnable\" # \"learnable\",\"fixed\"\n",
    "    args.input_embedding_dropout = 0.1\n",
    "    args.norm_type       = \"b\" # \"LayerNorm\" ,\"Batch\"\n",
    "    args.n_heads        = 8\n",
    "    args.dim_feedforward    = args.token_d_model*4\n",
    "    args.attn_dropout     = 0.1\n",
    "    args.activation      = \"relu\" # \"relu\", \"gelu\"\n",
    "    args.num_layers      = 4\n",
    "\n",
    "# training setting \n",
    "args.train_epochs       = 200\n",
    "\n",
    "args.learning_rate      = 0.001  \n",
    "args.learning_rate_patience  = 7\n",
    "args.learning_rate_factor   = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience    = 21\n",
    "\n",
    "args.use_gpu         = True if torch.cuda.is_available() else False\n",
    "args.gpu           = 0\n",
    "args.use_multi_gpu      = False\n",
    "\n",
    "args.optimizer        = \"Adam\"\n",
    "args.criterion        = \"CrossEntropy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc2e48cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "beginn to build model\n",
      "build embedding Done\n",
      "build encoder Done\n",
      "build transformer Done\n",
      "build prediction Done\n",
      "Build the conv_TS model!\n",
      "Parameter : 127302\n"
     ]
    }
   ],
   "source": [
    "exp = Exp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6633fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----------------------- load all the data -------------------\n",
      "----------------------- Get the Sliding Window -------------------\n",
      "The orginal class weights are :  [0.9968 1.1117 1.2208 0.966  0.9006 0.883 ]\n",
      "================ Given Mode ====================\n",
      "================ 1 CV ======================\n",
      "================ Build the model ================ \n",
      "beginn to build model\n",
      "build embedding Done\n",
      "build encoder Done\n",
      "build transformer Done\n",
      "build prediction Done\n",
      "Build the conv_TS model!\n",
      "================ the 1 th CV Experiment ================ \n",
      "After update the train test split , the class weight : [1.0043 1.1491 1.2304 0.9487 0.8872 0.8772]\n",
      "Train data number :  6984\n",
      "The number of classes is :  6\n",
      "The input_length  is :  128\n",
      "The channel_in is :  18\n",
      "Test data number :  2947\n",
      "Epoch: 1 cost time: 11.138622522354126\n",
      "Epoch: 1, Steps: 110 | Train Loss: 0.3377626  Vali Loss: 0.2052811 Vali Accuracy: 0.9256871  Vali weighted F1: 0.9256254  Vali macro F1 0.9274545 \n",
      "Validation loss decreased (inf --> 0.205281).  Saving model ...\n",
      "Epoch: 2 cost time: 11.110437870025635\n",
      "Epoch: 2, Steps: 110 | Train Loss: 0.1324021  Vali Loss: 0.2363037 Vali Accuracy: 0.9134713  Vali weighted F1: 0.9134609  Vali macro F1 0.9138491 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 3 cost time: 11.117513656616211\n",
      "Epoch: 3, Steps: 110 | Train Loss: 0.1170867  Vali Loss: 0.1979828 Vali Accuracy: 0.9222939  Vali weighted F1: 0.9218738  Vali macro F1 0.9226276 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.205281 --> 0.197983).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 11.1205153465271\n",
      "Epoch: 4, Steps: 110 | Train Loss: 0.1062869  Vali Loss: 0.2023090 Vali Accuracy: 0.9263658  Vali weighted F1: 0.9258858  Vali macro F1 0.9267232 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 5 cost time: 11.110681533813477\n",
      "Epoch: 5, Steps: 110 | Train Loss: 0.1154922  Vali Loss: 0.2317002 Vali Accuracy: 0.9267051  Vali weighted F1: 0.9265511  Vali macro F1 0.9268689 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 6 cost time: 11.116507768630981\n",
      "Epoch: 6, Steps: 110 | Train Loss: 0.0978804  Vali Loss: 0.2320831 Vali Accuracy: 0.9182219  Vali weighted F1: 0.9168642  Vali macro F1 0.9175240 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 7 cost time: 11.108503818511963\n",
      "Epoch: 7, Steps: 110 | Train Loss: 0.0871094  Vali Loss: 0.2856153 Vali Accuracy: 0.9199186  Vali weighted F1: 0.9190781  Vali macro F1 0.9191728 \n",
      "EarlyStopping counter: 4 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 8 cost time: 11.110668897628784\n",
      "Epoch: 8, Steps: 110 | Train Loss: 0.0726485  Vali Loss: 0.2258966 Vali Accuracy: 0.9362063  Vali weighted F1: 0.9360292  Vali macro F1 0.9365821 \n",
      "EarlyStopping counter: 5 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 9 cost time: 11.110451221466064\n",
      "Epoch: 9, Steps: 110 | Train Loss: 0.0760516  Vali Loss: 0.1967395 Vali Accuracy: 0.9406176  Vali weighted F1: 0.9402636  Vali macro F1 0.9404444 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.197983 --> 0.196739).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 10 cost time: 11.106495141983032\n",
      "Epoch: 10, Steps: 110 | Train Loss: 0.0589004  Vali Loss: 0.1879843 Vali Accuracy: 0.9450288  Vali weighted F1: 0.9446886  Vali macro F1 0.9442663 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.196739 --> 0.187984).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 11 cost time: 11.115514039993286\n",
      "Epoch: 11, Steps: 110 | Train Loss: 0.0429458  Vali Loss: 0.2237058 Vali Accuracy: 0.9416356  Vali weighted F1: 0.9417076  Vali macro F1 0.9411214 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 12 cost time: 11.110512256622314\n",
      "Epoch: 12, Steps: 110 | Train Loss: 0.0461517  Vali Loss: 0.2475374 Vali Accuracy: 0.9382423  Vali weighted F1: 0.9380117  Vali macro F1 0.9378033 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 13 cost time: 11.11549711227417\n",
      "Epoch: 13, Steps: 110 | Train Loss: 0.0579638  Vali Loss: 0.2586148 Vali Accuracy: 0.9334917  Vali weighted F1: 0.9327866  Vali macro F1 0.9325458 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 14 cost time: 11.104762554168701\n",
      "Epoch: 14, Steps: 110 | Train Loss: 0.0466362  Vali Loss: 0.2285464 Vali Accuracy: 0.9446895  Vali weighted F1: 0.9442265  Vali macro F1 0.9446775 \n",
      "EarlyStopping counter: 4 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 15 cost time: 11.110594749450684\n",
      "Epoch: 15, Steps: 110 | Train Loss: 0.0355775  Vali Loss: 0.2004612 Vali Accuracy: 0.9460468  Vali weighted F1: 0.9456951  Vali macro F1 0.9462347 \n",
      "EarlyStopping counter: 5 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 16 cost time: 11.126516580581665\n",
      "Epoch: 16, Steps: 110 | Train Loss: 0.0415727  Vali Loss: 0.2021241 Vali Accuracy: 0.9406176  Vali weighted F1: 0.9405116  Vali macro F1 0.9403928 \n",
      "EarlyStopping counter: 6 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 17 cost time: 11.110574007034302\n",
      "Epoch: 17, Steps: 110 | Train Loss: 0.0349336  Vali Loss: 0.1749827 Vali Accuracy: 0.9535120  Vali weighted F1: 0.9534250  Vali macro F1 0.9537354 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.187984 --> 0.174983).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 18 cost time: 11.125586032867432\n",
      "Epoch: 18, Steps: 110 | Train Loss: 0.0215171  Vali Loss: 0.2187729 Vali Accuracy: 0.9548694  Vali weighted F1: 0.9547653  Vali macro F1 0.9551714 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 19 cost time: 11.109301805496216\n",
      "Epoch: 19, Steps: 110 | Train Loss: 0.0163974  Vali Loss: 0.2227148 Vali Accuracy: 0.9518154  Vali weighted F1: 0.9515706  Vali macro F1 0.9519935 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 20 cost time: 11.117891073226929\n",
      "Epoch: 20, Steps: 110 | Train Loss: 0.0222342  Vali Loss: 0.2818682 Vali Accuracy: 0.9351883  Vali weighted F1: 0.9349491  Vali macro F1 0.9351129 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 21 cost time: 11.125060081481934\n",
      "Epoch: 21, Steps: 110 | Train Loss: 0.0206268  Vali Loss: 0.2699009 Vali Accuracy: 0.9457075  Vali weighted F1: 0.9453169  Vali macro F1 0.9451306 \n",
      "EarlyStopping counter: 4 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 22 cost time: 11.111499309539795\n",
      "Epoch: 22, Steps: 110 | Train Loss: 0.0230790  Vali Loss: 0.2747914 Vali Accuracy: 0.9331524  Vali weighted F1: 0.9326908  Vali macro F1 0.9312978 \n",
      "EarlyStopping counter: 5 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 23 cost time: 11.120190143585205\n",
      "Epoch: 23, Steps: 110 | Train Loss: 0.0326863  Vali Loss: 0.3235271 Vali Accuracy: 0.9273838  Vali weighted F1: 0.9271504  Vali macro F1 0.9269493 \n",
      "EarlyStopping counter: 6 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 24 cost time: 11.108662843704224\n",
      "Epoch: 24, Steps: 110 | Train Loss: 0.0773693  Vali Loss: 0.2836189 Vali Accuracy: 0.9375636  Vali weighted F1: 0.9375698  Vali macro F1 0.9370543 \n",
      "EarlyStopping counter: 7 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 25 cost time: 11.113497257232666\n",
      "Epoch: 25, Steps: 110 | Train Loss: 0.0187849  Vali Loss: 0.2262344 Vali Accuracy: 0.9484221  Vali weighted F1: 0.9480763  Vali macro F1 0.9487100 \n",
      "EarlyStopping counter: 8 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 26 cost time: 11.11048674583435\n",
      "Epoch: 26, Steps: 110 | Train Loss: 0.0115743  Vali Loss: 0.2175266 Vali Accuracy: 0.9504581  Vali weighted F1: 0.9503056  Vali macro F1 0.9509452 \n",
      "EarlyStopping counter: 9 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 27 cost time: 11.109503746032715\n",
      "Epoch: 27, Steps: 110 | Train Loss: 0.0103995  Vali Loss: 0.2257511 Vali Accuracy: 0.9511367  Vali weighted F1: 0.9509381  Vali macro F1 0.9514709 \n",
      "EarlyStopping counter: 10 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 28 cost time: 11.124912977218628\n",
      "Epoch: 28, Steps: 110 | Train Loss: 0.0101494  Vali Loss: 0.2321312 Vali Accuracy: 0.9501188  Vali weighted F1: 0.9498908  Vali macro F1 0.9504014 \n",
      "EarlyStopping counter: 11 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 cost time: 11.114818096160889\n",
      "Epoch: 29, Steps: 110 | Train Loss: 0.0100938  Vali Loss: 0.2403682 Vali Accuracy: 0.9487615  Vali weighted F1: 0.9484860  Vali macro F1 0.9490517 \n",
      "EarlyStopping counter: 12 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 30 cost time: 11.11051869392395\n",
      "Epoch: 30, Steps: 110 | Train Loss: 0.0060465  Vali Loss: 0.2398306 Vali Accuracy: 0.9501188  Vali weighted F1: 0.9498781  Vali macro F1 0.9505077 \n",
      "EarlyStopping counter: 13 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 31 cost time: 11.108169794082642\n",
      "Epoch: 31, Steps: 110 | Train Loss: 0.0061210  Vali Loss: 0.2497714 Vali Accuracy: 0.9504581  Vali weighted F1: 0.9501883  Vali macro F1 0.9507222 \n",
      "EarlyStopping counter: 14 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 32 cost time: 11.12052059173584\n",
      "Epoch: 32, Steps: 110 | Train Loss: 0.0064353  Vali Loss: 0.2468328 Vali Accuracy: 0.9511367  Vali weighted F1: 0.9508834  Vali macro F1 0.9513949 \n",
      "EarlyStopping counter: 15 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 33 cost time: 11.107495307922363\n",
      "Epoch: 33, Steps: 110 | Train Loss: 0.0051870  Vali Loss: 0.2469755 Vali Accuracy: 0.9504581  Vali weighted F1: 0.9501996  Vali macro F1 0.9507357 \n",
      "EarlyStopping counter: 16 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 34 cost time: 11.109504699707031\n",
      "Epoch: 34, Steps: 110 | Train Loss: 0.0050739  Vali Loss: 0.2448220 Vali Accuracy: 0.9511367  Vali weighted F1: 0.9509151  Vali macro F1 0.9514332 \n",
      "EarlyStopping counter: 17 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 35 cost time: 11.118507385253906\n",
      "Epoch: 35, Steps: 110 | Train Loss: 0.0057340  Vali Loss: 0.2457433 Vali Accuracy: 0.9504581  Vali weighted F1: 0.9502215  Vali macro F1 0.9507620 \n",
      "EarlyStopping counter: 18 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 36 cost time: 11.108349800109863\n",
      "Epoch: 36, Steps: 110 | Train Loss: 0.0052363  Vali Loss: 0.2467826 Vali Accuracy: 0.9501188  Vali weighted F1: 0.9498744  Vali macro F1 0.9504262 \n",
      "EarlyStopping counter: 19 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 37 cost time: 11.118599891662598\n",
      "Epoch: 37, Steps: 110 | Train Loss: 0.0074990  Vali Loss: 0.2466728 Vali Accuracy: 0.9494401  Vali weighted F1: 0.9491961  Vali macro F1 0.9497151 \n",
      "EarlyStopping counter: 20 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 38 cost time: 11.108498334884644\n",
      "Epoch: 38, Steps: 110 | Train Loss: 0.0053083  Vali Loss: 0.2443986 Vali Accuracy: 0.9507974  Vali weighted F1: 0.9505835  Vali macro F1 0.9510574 \n",
      "EarlyStopping counter: 21 out of 21\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "exp.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eeaace",
   "metadata": {},
   "source": [
    "# OPPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bfb7b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()    \n",
    "args.root_path =  r\"D:\\TECO\\Paper\\datasets\\Opportunity_Dataset\\dataset\"  # -----------\n",
    "args.freq_save_path = r\"D:\\TECO\\Paper\\Final_version\\Freq_data\"\n",
    "args.data_name = \"oppo\"  # -----------\n",
    "\n",
    "args.difference = True \n",
    "\n",
    "args.sampling_freq =   30   # -----------\n",
    "args.windowsize = int(1* args.sampling_freq) # -----------\n",
    "args.displacement =  int(0.5 * args.windowsize)  # -----------\n",
    "args.weighted  = False\n",
    "args.drop_long = False\n",
    "args.datanorm_type = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "args.wavename = \"morl\"\n",
    "\n",
    "# input information\n",
    "args.c_in      =  77*2 # it depends on the dataset # -----------\n",
    "args.input_length  =  args.windowsize   # it depends on the dataset # -----------\n",
    "args.num_classes  =  18 # -----------\n",
    "\n",
    "args.batch_size = 64\n",
    "args.shuffle = True\n",
    "args.drop_last = False\n",
    "args.train_vali_quote = 0.95\n",
    "\n",
    "\n",
    "\n",
    "args.exp_mode = \"Given\"\n",
    "args.model_type = \"time\"\n",
    "args.cls_token = True\n",
    "\n",
    "if args.model_type  in [\"time\",\"freq\",\"cross\"]:\n",
    "    args.light_weight      = False\n",
    "    # embedding \n",
    "    args.spectrogram      = True if args.model_type in [\"freq\",\"cross\"] else False\n",
    "    args.wavelet        = 'morl'\n",
    "\n",
    "    args.token_d_model     =  48\n",
    "    args.token_kernel_size   =  3\n",
    "    args.token_stride      =  1\n",
    "    args.token_conv_bias    =  True\n",
    "    args.token_activation    =  \"hardswish\"\n",
    "    args.token_norm       =  \"layer\"\n",
    "    args.token_n_layers     =  2\n",
    "    args.token_in_planes    =  48\n",
    "    args.token_max_pool     =  False\n",
    "    args.token_pool_kernel_size =  3\n",
    "    args.token_pool_stride    =  1\n",
    "    args.token_pool_pad      =  1\n",
    "    args.positional_embedding   = \"learnable\"    #None , \"learnable\" , \"sinus\"\n",
    "    args.input_embedding_dropout = 0.1\n",
    "\n",
    "    # Encoder\n",
    "    args.bias          = False\n",
    "    args.padding_mode      = \"replicate\"\n",
    "\n",
    "    args.single_depth        = 2\n",
    "    \n",
    "    # only model type == cross\n",
    "    args.cross_depth    = 1\n",
    "    args.t_depth        = 2\n",
    "    args.cross_atten_depth = 1\n",
    "    \n",
    "    args.distil         = False\n",
    "\n",
    "    #args.mask_flag                  = False\n",
    "    args.attention_layer_types = \"Full\" #[\"Full\",\"LocalSymmetry\",\"LocLogSymmetry\"]\n",
    "    args.attention_dropout   = 0.1   # attention map 也就是score的drop\n",
    "    args.output_attention    = True\n",
    "\n",
    "    args.n_heads        = 6\n",
    "    args.d_keys         = None\n",
    "    args.d_values        = None\n",
    "    args.causal_kernel_size   = 3\n",
    "    args.value_kernel_size   = 3\n",
    "    args.projection_dropout   = 0.1\n",
    "\n",
    "    args.feedforward_dim    = None\n",
    "    args.feedforward_dropout  = 0.1\n",
    "    args.feedforward_activation = \"hardswish\"\n",
    "    args.feedforward_norm_type = \"layer\"\n",
    "    args.forward_kernel_size  = 3\n",
    "    args.conv_activation    = \"hardswish\"\n",
    "    args.conv_norm       = \"layer\"\n",
    "else:\n",
    "    args.token_d_model     = 128\n",
    "    args.positional_embedding  = \"learnable\" # \"learnable\",\"fixed\"\n",
    "    args.input_embedding_dropout = 0.1\n",
    "    args.norm_type       = \"b\" # \"LayerNorm\" ,\"Batch\"\n",
    "    args.n_heads        = 8\n",
    "    args.dim_feedforward    = args.token_d_model*4\n",
    "    args.attn_dropout     = 0.1\n",
    "    args.activation      = \"relu\" # \"relu\", \"gelu\"\n",
    "    args.num_layers      = 4\n",
    "\n",
    "# training setting \n",
    "args.train_epochs       = 200\n",
    "\n",
    "args.learning_rate      = 0.001  \n",
    "args.learning_rate_patience  = 7\n",
    "args.learning_rate_factor   = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience    = 21\n",
    "\n",
    "args.use_gpu         = True if torch.cuda.is_available() else False\n",
    "args.gpu           = 0\n",
    "args.use_multi_gpu      = False\n",
    "\n",
    "args.optimizer        = \"Adam\"\n",
    "args.criterion        = \"CrossEntropy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76bb9014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "beginn to build model\n",
      "build embedding Done\n",
      "build encoder Done\n",
      "build transformer Done\n",
      "build prediction Done\n",
      "Build the conv_TS model!\n",
      "Parameter : 142770\n",
      " ----------------------- load all the data -------------------\n",
      "----------------------- Get the Sliding Window -------------------\n",
      "The orginal class weights are :  [ 0.0731  3.7243  3.5841  3.9674  3.8138  3.2571  3.7243  5.0558  5.5574\n",
      "  7.9347 10.4634  8.7355 10.4634  6.5516  6.8337  3.0982  0.9008  6.8666]\n",
      "================ Given Mode ====================\n",
      "================ 1 CV ======================\n",
      "================ Build the model ================ \n",
      "beginn to build model\n",
      "build embedding Done\n",
      "build encoder Done\n",
      "build transformer Done\n",
      "build prediction Done\n",
      "Build the conv_TS model!\n",
      "================ the 1 th CV Experiment ================ \n",
      "After update the train test split , the class weight : [0.0748 3.3789 3.374  3.621  3.5383 3.3448 3.6609 4.7931 5.098  7.1309\n",
      " 9.8922 7.907  9.3737 6.0696 6.2659 2.8454 0.8288 6.9601]\n",
      "Train data number :  41844\n",
      "The number of classes is :  18\n",
      "The input_length  is :  30\n",
      "The channel_in is :  154\n",
      "Test data number :  7370\n",
      "Epoch: 1 cost time: 21.215805768966675\n",
      "Epoch: 1, Steps: 654 | Train Loss: 0.4582865  Vali Loss: 0.3356853 Vali Accuracy: 0.9077341  Vali weighted F1: 0.8981667  Vali macro F1 0.4809507 \n",
      "Validation loss decreased (inf --> 0.335685).  Saving model ...\n",
      "Epoch: 2 cost time: 21.195777893066406\n",
      "Epoch: 2, Steps: 654 | Train Loss: 0.2548733  Vali Loss: 0.3355843 Vali Accuracy: 0.8895522  Vali weighted F1: 0.8983921  Vali macro F1 0.5987463 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.335685 --> 0.335584).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 21.198787689208984\n",
      "Epoch: 3, Steps: 654 | Train Loss: 0.1986301  Vali Loss: 0.3730621 Vali Accuracy: 0.8696065  Vali weighted F1: 0.8842180  Vali macro F1 0.6044465 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 4 cost time: 21.21379041671753\n",
      "Epoch: 4, Steps: 654 | Train Loss: 0.1667091  Vali Loss: 0.2779499 Vali Accuracy: 0.9176391  Vali weighted F1: 0.9160797  Vali macro F1 0.6414021 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.335584 --> 0.277950).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 21.151776790618896\n",
      "Epoch: 5, Steps: 654 | Train Loss: 0.1508020  Vali Loss: 0.2518754 Vali Accuracy: 0.9274084  Vali weighted F1: 0.9242058  Vali macro F1 0.6455960 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.277950 --> 0.251875).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 6 cost time: 21.279805421829224\n",
      "Epoch: 6, Steps: 654 | Train Loss: 0.1315924  Vali Loss: 0.2804554 Vali Accuracy: 0.9218453  Vali weighted F1: 0.9206648  Vali macro F1 0.6363404 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 7 cost time: 21.302802562713623\n",
      "Epoch: 7, Steps: 654 | Train Loss: 0.1208441  Vali Loss: 0.2514275 Vali Accuracy: 0.9327001  Vali weighted F1: 0.9289269  Vali macro F1 0.6829465 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.251875 --> 0.251427).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 8 cost time: 21.234786987304688\n",
      "Epoch: 8, Steps: 654 | Train Loss: 0.1132847  Vali Loss: 0.2636017 Vali Accuracy: 0.9226594  Vali weighted F1: 0.9234276  Vali macro F1 0.6440960 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 9 cost time: 21.18777632713318\n",
      "Epoch: 9, Steps: 654 | Train Loss: 0.1061174  Vali Loss: 0.2824745 Vali Accuracy: 0.9295794  Vali weighted F1: 0.9273044  Vali macro F1 0.6440652 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 10 cost time: 21.245789527893066\n",
      "Epoch: 10, Steps: 654 | Train Loss: 0.0980660  Vali Loss: 0.3167986 Vali Accuracy: 0.9238806  Vali weighted F1: 0.9205238  Vali macro F1 0.6390216 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 11 cost time: 21.267794370651245\n",
      "Epoch: 11, Steps: 654 | Train Loss: 0.0904808  Vali Loss: 0.2992681 Vali Accuracy: 0.9293080  Vali weighted F1: 0.9268648  Vali macro F1 0.6610682 \n",
      "EarlyStopping counter: 4 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 12 cost time: 21.255791902542114\n",
      "Epoch: 12, Steps: 654 | Train Loss: 0.0890997  Vali Loss: 0.2800688 Vali Accuracy: 0.9259159  Vali weighted F1: 0.9246554  Vali macro F1 0.6443729 \n",
      "EarlyStopping counter: 5 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 13 cost time: 21.18876814842224\n",
      "Epoch: 13, Steps: 654 | Train Loss: 0.0843296  Vali Loss: 0.2968801 Vali Accuracy: 0.9253731  Vali weighted F1: 0.9242886  Vali macro F1 0.6437289 \n",
      "EarlyStopping counter: 6 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 14 cost time: 21.207789182662964\n",
      "Epoch: 14, Steps: 654 | Train Loss: 0.0787550  Vali Loss: 0.3475685 Vali Accuracy: 0.9198100  Vali weighted F1: 0.9163310  Vali macro F1 0.6151457 \n",
      "EarlyStopping counter: 7 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 15 cost time: 21.263050079345703\n",
      "Epoch: 15, Steps: 654 | Train Loss: 0.0387163  Vali Loss: 0.3029682 Vali Accuracy: 0.9291723  Vali weighted F1: 0.9279121  Vali macro F1 0.6772512 \n",
      "EarlyStopping counter: 8 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 16 cost time: 21.26825523376465\n",
      "Epoch: 16, Steps: 654 | Train Loss: 0.0286012  Vali Loss: 0.3062000 Vali Accuracy: 0.9264586  Vali weighted F1: 0.9257195  Vali macro F1 0.6704006 \n",
      "EarlyStopping counter: 9 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 17 cost time: 21.13976526260376\n",
      "Epoch: 17, Steps: 654 | Train Loss: 0.0233886  Vali Loss: 0.3301417 Vali Accuracy: 0.9275441  Vali weighted F1: 0.9271868  Vali macro F1 0.6717651 \n",
      "EarlyStopping counter: 10 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 18 cost time: 21.11476755142212\n",
      "Epoch: 18, Steps: 654 | Train Loss: 0.0203850  Vali Loss: 0.3113796 Vali Accuracy: 0.9298507  Vali weighted F1: 0.9289977  Vali macro F1 0.6690849 \n",
      "EarlyStopping counter: 11 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 19 cost time: 21.175773859024048\n",
      "Epoch: 19, Steps: 654 | Train Loss: 0.0180813  Vali Loss: 0.3321928 Vali Accuracy: 0.9299864  Vali weighted F1: 0.9290833  Vali macro F1 0.6826652 \n",
      "EarlyStopping counter: 12 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 20 cost time: 21.13976550102234\n",
      "Epoch: 20, Steps: 654 | Train Loss: 0.0160864  Vali Loss: 0.3401698 Vali Accuracy: 0.9283582  Vali weighted F1: 0.9283238  Vali macro F1 0.6804396 \n",
      "EarlyStopping counter: 13 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 21 cost time: 21.135772943496704\n",
      "Epoch: 21, Steps: 654 | Train Loss: 0.0144146  Vali Loss: 0.3439956 Vali Accuracy: 0.9327001  Vali weighted F1: 0.9313558  Vali macro F1 0.6849306 \n",
      "EarlyStopping counter: 14 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 22 cost time: 21.24179697036743\n",
      "Epoch: 22, Steps: 654 | Train Loss: 0.0118206  Vali Loss: 0.3464463 Vali Accuracy: 0.9316147  Vali weighted F1: 0.9304767  Vali macro F1 0.6811132 \n",
      "EarlyStopping counter: 15 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 23 cost time: 21.217791080474854\n",
      "Epoch: 23, Steps: 654 | Train Loss: 0.0107851  Vali Loss: 0.3491626 Vali Accuracy: 0.9316147  Vali weighted F1: 0.9302632  Vali macro F1 0.6819317 \n",
      "EarlyStopping counter: 16 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 24 cost time: 21.23336410522461\n",
      "Epoch: 24, Steps: 654 | Train Loss: 0.0108075  Vali Loss: 0.3511247 Vali Accuracy: 0.9318860  Vali weighted F1: 0.9303040  Vali macro F1 0.6806186 \n",
      "EarlyStopping counter: 17 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 25 cost time: 21.23563575744629\n",
      "Epoch: 25, Steps: 654 | Train Loss: 0.0097225  Vali Loss: 0.3550480 Vali Accuracy: 0.9312076  Vali weighted F1: 0.9298045  Vali macro F1 0.6773723 \n",
      "EarlyStopping counter: 18 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 26 cost time: 21.317805767059326\n",
      "Epoch: 26, Steps: 654 | Train Loss: 0.0092913  Vali Loss: 0.3570247 Vali Accuracy: 0.9310719  Vali weighted F1: 0.9296661  Vali macro F1 0.6769021 \n",
      "EarlyStopping counter: 19 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 cost time: 21.30779528617859\n",
      "Epoch: 27, Steps: 654 | Train Loss: 0.0098714  Vali Loss: 0.3553897 Vali Accuracy: 0.9309362  Vali weighted F1: 0.9294459  Vali macro F1 0.6753997 \n",
      "EarlyStopping counter: 20 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 28 cost time: 21.2407968044281\n",
      "Epoch: 28, Steps: 654 | Train Loss: 0.0093013  Vali Loss: 0.3588837 Vali Accuracy: 0.9318860  Vali weighted F1: 0.9301987  Vali macro F1 0.6784400 \n",
      "EarlyStopping counter: 21 out of 21\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "exp = Exp(args)\n",
    "exp.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2823327a",
   "metadata": {},
   "source": [
    "# USCHAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2694eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()    \n",
    "args.root_path =  r\"D:\\TECO\\Paper\\datasets\\USC_HAD_Dataset\"  # -----------\n",
    "args.freq_save_path = r\"D:\\TECO\\Paper\\Final_version\\Freq_data\"\n",
    "args.data_name = \"uschad\"  # -----------\n",
    "\n",
    "args.difference = True \n",
    "\n",
    "args.sampling_freq =   100   # -----------\n",
    "args.windowsize = int(1.28 * args.sampling_freq) # -----------\n",
    "args.displacement =  int(0.5 * args.windowsize)  # -----------\n",
    "args.weighted  = False\n",
    "args.drop_long = False\n",
    "args.datanorm_type = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "args.wavename = \"morl\"\n",
    "\n",
    "# input information\n",
    "args.c_in      =  12 # it depends on the dataset # -----------\n",
    "args.input_length  =  128  # it depends on the dataset # -----------\n",
    "args.num_classes  =  12 # -----------\n",
    "\n",
    "args.batch_size = 64\n",
    "args.shuffle = True\n",
    "args.drop_last = False\n",
    "args.train_vali_quote = 0.95\n",
    "\n",
    "\n",
    "\n",
    "args.exp_mode = \"Given\"\n",
    "args.model_type = \"time\"\n",
    "args.cls_token = True\n",
    "\n",
    "if args.model_type  in [\"time\",\"freq\",\"cross\"]:\n",
    "    args.light_weight      = False\n",
    "    # embedding \n",
    "    args.spectrogram      = True if args.model_type in [\"freq\",\"cross\"] else False\n",
    "    args.wavelet        = 'morl'\n",
    "\n",
    "    args.token_d_model     =  48\n",
    "    args.token_kernel_size   =  3\n",
    "    args.token_stride      =  1\n",
    "    args.token_conv_bias    =  True\n",
    "    args.token_activation    =  \"hardswish\"\n",
    "    args.token_norm       =  \"layer\"\n",
    "    args.token_n_layers     =  2\n",
    "    args.token_in_planes    =  48\n",
    "    args.token_max_pool     =  False\n",
    "    args.token_pool_kernel_size =  3\n",
    "    args.token_pool_stride    =  1\n",
    "    args.token_pool_pad      =  1\n",
    "    args.positional_embedding   = \"learnable\"    #None , \"learnable\" , \"sinus\"\n",
    "    args.input_embedding_dropout = 0.1\n",
    "\n",
    "    # Encoder\n",
    "    args.bias          = False\n",
    "    args.padding_mode      = \"replicate\"\n",
    "\n",
    "    args.single_depth        = 2\n",
    "    \n",
    "    # only model type == cross\n",
    "    args.cross_depth    = 1\n",
    "    args.t_depth        = 2\n",
    "    args.cross_atten_depth = 1\n",
    "    \n",
    "    args.distil         = False\n",
    "\n",
    "    #args.mask_flag                  = False\n",
    "    args.attention_layer_types = \"Full\" #[\"Full\",\"LocalSymmetry\",\"LocLogSymmetry\"]\n",
    "    args.attention_dropout   = 0.1   # attention map 也就是score的drop\n",
    "    args.output_attention    = True\n",
    "\n",
    "    args.n_heads        = 6\n",
    "    args.d_keys         = None\n",
    "    args.d_values        = None\n",
    "    args.causal_kernel_size   = 3\n",
    "    args.value_kernel_size   = 3\n",
    "    args.projection_dropout   = 0.1\n",
    "\n",
    "    args.feedforward_dim    = None\n",
    "    args.feedforward_dropout  = 0.1\n",
    "    args.feedforward_activation = \"hardswish\"\n",
    "    args.feedforward_norm_type = \"layer\"\n",
    "    args.forward_kernel_size  = 3\n",
    "    args.conv_activation    = \"hardswish\"\n",
    "    args.conv_norm       = \"layer\"\n",
    "else:\n",
    "    args.token_d_model     = 128\n",
    "    args.positional_embedding  = \"learnable\" # \"learnable\",\"fixed\"\n",
    "    args.input_embedding_dropout = 0.1\n",
    "    args.norm_type       = \"b\" # \"LayerNorm\" ,\"Batch\"\n",
    "    args.n_heads        = 8\n",
    "    args.dim_feedforward    = args.token_d_model*4\n",
    "    args.attn_dropout     = 0.1\n",
    "    args.activation      = \"relu\" # \"relu\", \"gelu\"\n",
    "    args.num_layers      = 4\n",
    "\n",
    "# training setting \n",
    "args.train_epochs       = 200\n",
    "\n",
    "args.learning_rate      = 0.001  \n",
    "args.learning_rate_patience  = 7\n",
    "args.learning_rate_factor   = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience    = 21\n",
    "\n",
    "args.use_gpu         = True if torch.cuda.is_available() else False\n",
    "args.gpu           = 0\n",
    "args.use_multi_gpu      = False\n",
    "\n",
    "args.optimizer        = \"Adam\"\n",
    "args.criterion        = \"CrossEntropy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8db7146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "beginn to build model\n",
      "build embedding Done\n",
      "build encoder Done\n",
      "build transformer Done\n",
      "build prediction Done\n",
      "Build the conv_TS model!\n",
      "Parameter : 126732\n",
      " ----------------------- load all the data -------------------\n",
      "----------------------- Get the Sliding Window -------------------\n",
      "The orginal class weights are :  [0.6078 0.9031 0.847  1.1098 1.1947 1.342  2.2669 0.8929 0.9933 0.6159\n",
      " 1.4345 1.4397]\n",
      "================ Given Mode ====================\n",
      "================ 1 CV ======================\n",
      "================ Build the model ================ \n",
      "beginn to build model\n",
      "build embedding Done\n",
      "build encoder Done\n",
      "build transformer Done\n",
      "build prediction Done\n",
      "Build the conv_TS model!\n",
      "================ the 1 th CV Experiment ================ \n",
      "After update the train test split , the class weight : [0.6362 0.9053 0.8491 1.013  1.0941 1.4612 2.3149 0.9267 0.9769 0.6439\n",
      " 1.3663 1.3499]\n",
      "Train data number :  33807\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  12\n",
      "Test data number :  7121\n",
      "Epoch: 1 cost time: 53.47283911705017\n",
      "Epoch: 1, Steps: 529 | Train Loss: 0.4575341  Vali Loss: 1.9148518 Vali Accuracy: 0.4989468  Vali weighted F1: 0.4800561  Vali macro F1 0.4456901 \n",
      "Validation loss decreased (inf --> 1.914852).  Saving model ...\n",
      "Epoch: 2 cost time: 53.64151072502136\n",
      "Epoch: 2, Steps: 529 | Train Loss: 0.2440132  Vali Loss: 1.9829662 Vali Accuracy: 0.4881337  Vali weighted F1: 0.5069615  Vali macro F1 0.4705981 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 3 cost time: 53.640196561813354\n",
      "Epoch: 3, Steps: 529 | Train Loss: 0.2211774  Vali Loss: 1.1429927 Vali Accuracy: 0.6397978  Vali weighted F1: 0.6448253  Vali macro F1 0.6051451 \n",
      "new best score!!!!\n",
      "Validation loss decreased (1.914852 --> 1.142993).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 53.64725351333618\n",
      "Epoch: 4, Steps: 529 | Train Loss: 0.2029520  Vali Loss: 2.0484738 Vali Accuracy: 0.5017554  Vali weighted F1: 0.5082209  Vali macro F1 0.4637719 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 5 cost time: 53.64361047744751\n",
      "Epoch: 5, Steps: 529 | Train Loss: 0.1922851  Vali Loss: 1.9204759 Vali Accuracy: 0.5311052  Vali weighted F1: 0.5506433  Vali macro F1 0.4903935 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 6 cost time: 53.681623220443726\n",
      "Epoch: 6, Steps: 529 | Train Loss: 0.1854762  Vali Loss: 2.9493171 Vali Accuracy: 0.4374386  Vali weighted F1: 0.4602477  Vali macro F1 0.4410633 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 7 cost time: 54.009061336517334\n",
      "Epoch: 7, Steps: 529 | Train Loss: 0.1767913  Vali Loss: 1.9950382 Vali Accuracy: 0.5329308  Vali weighted F1: 0.5446498  Vali macro F1 0.5038867 \n",
      "EarlyStopping counter: 4 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 8 cost time: 54.023170948028564\n",
      "Epoch: 8, Steps: 529 | Train Loss: 0.1692327  Vali Loss: 2.2839004 Vali Accuracy: 0.5322286  Vali weighted F1: 0.5403454  Vali macro F1 0.5050154 \n",
      "EarlyStopping counter: 5 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 9 cost time: 54.014399766922\n",
      "Epoch: 9, Steps: 529 | Train Loss: 0.1655382  Vali Loss: 2.5466897 Vali Accuracy: 0.4653841  Vali weighted F1: 0.4697288  Vali macro F1 0.4519285 \n",
      "EarlyStopping counter: 6 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 10 cost time: 54.03932023048401\n",
      "Epoch: 10, Steps: 529 | Train Loss: 0.1615525  Vali Loss: 1.8495668 Vali Accuracy: 0.5680382  Vali weighted F1: 0.5805578  Vali macro F1 0.5300682 \n",
      "EarlyStopping counter: 7 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 11 cost time: 54.0167191028595\n",
      "Epoch: 11, Steps: 529 | Train Loss: 0.1294760  Vali Loss: 2.4613739 Vali Accuracy: 0.5160792  Vali weighted F1: 0.5267511  Vali macro F1 0.4985385 \n",
      "EarlyStopping counter: 8 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 12 cost time: 54.01933217048645\n",
      "Epoch: 12, Steps: 529 | Train Loss: 0.1187594  Vali Loss: 2.2304580 Vali Accuracy: 0.5297009  Vali weighted F1: 0.5382385  Vali macro F1 0.5112347 \n",
      "EarlyStopping counter: 9 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 13 cost time: 54.08475923538208\n",
      "Epoch: 13, Steps: 529 | Train Loss: 0.1162124  Vali Loss: 2.4639280 Vali Accuracy: 0.5082151  Vali weighted F1: 0.5219032  Vali macro F1 0.4922613 \n",
      "EarlyStopping counter: 10 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 14 cost time: 54.0348117351532\n",
      "Epoch: 14, Steps: 529 | Train Loss: 0.1127477  Vali Loss: 2.4930334 Vali Accuracy: 0.5041427  Vali weighted F1: 0.5163726  Vali macro F1 0.4854949 \n",
      "EarlyStopping counter: 11 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 15 cost time: 54.016542196273804\n",
      "Epoch: 15, Steps: 529 | Train Loss: 0.1108739  Vali Loss: 3.0013946 Vali Accuracy: 0.4714226  Vali weighted F1: 0.4666011  Vali macro F1 0.4716697 \n",
      "EarlyStopping counter: 12 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 16 cost time: 54.01434874534607\n",
      "Epoch: 16, Steps: 529 | Train Loss: 0.1094868  Vali Loss: 2.7192848 Vali Accuracy: 0.5011937  Vali weighted F1: 0.5127494  Vali macro F1 0.4858314 \n",
      "EarlyStopping counter: 13 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 17 cost time: 54.01479196548462\n",
      "Epoch: 17, Steps: 529 | Train Loss: 0.1090051  Vali Loss: 2.6470548 Vali Accuracy: 0.5031597  Vali weighted F1: 0.5147296  Vali macro F1 0.4908798 \n",
      "EarlyStopping counter: 14 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 18 cost time: 54.01582908630371\n",
      "Epoch: 18, Steps: 529 | Train Loss: 0.1040844  Vali Loss: 2.6113654 Vali Accuracy: 0.5077938  Vali weighted F1: 0.5179876  Vali macro F1 0.4941215 \n",
      "EarlyStopping counter: 15 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 19 cost time: 54.029680013656616\n",
      "Epoch: 19, Steps: 529 | Train Loss: 0.1030952  Vali Loss: 2.6041793 Vali Accuracy: 0.5101812  Vali weighted F1: 0.5185147  Vali macro F1 0.4956691 \n",
      "EarlyStopping counter: 16 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 20 cost time: 54.01110887527466\n",
      "Epoch: 20, Steps: 529 | Train Loss: 0.1028823  Vali Loss: 2.6226012 Vali Accuracy: 0.5093386  Vali weighted F1: 0.5178866  Vali macro F1 0.4948114 \n",
      "EarlyStopping counter: 17 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 21 cost time: 53.9946711063385\n",
      "Epoch: 21, Steps: 529 | Train Loss: 0.1028090  Vali Loss: 2.6478174 Vali Accuracy: 0.5082151  Vali weighted F1: 0.5171497  Vali macro F1 0.4940301 \n",
      "EarlyStopping counter: 18 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 22 cost time: 54.064765214920044\n",
      "Epoch: 22, Steps: 529 | Train Loss: 0.1024792  Vali Loss: 2.6226756 Vali Accuracy: 0.5117259  Vali weighted F1: 0.5210336  Vali macro F1 0.4945409 \n",
      "EarlyStopping counter: 19 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 23 cost time: 53.981855630874634\n",
      "Epoch: 23, Steps: 529 | Train Loss: 0.1020860  Vali Loss: 2.6543599 Vali Accuracy: 0.5110237  Vali weighted F1: 0.5195727  Vali macro F1 0.4946708 \n",
      "EarlyStopping counter: 20 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 24 cost time: 53.98944973945618\n",
      "Epoch: 24, Steps: 529 | Train Loss: 0.1020901  Vali Loss: 2.6495299 Vali Accuracy: 0.5106024  Vali weighted F1: 0.5190699  Vali macro F1 0.4939593 \n",
      "EarlyStopping counter: 21 out of 21\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "exp = Exp(args)\n",
    "exp.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacc98d",
   "metadata": {},
   "source": [
    "# Daphnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0f44db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()    \n",
    "args.root_path =  r\"D:\\TECO\\Paper\\datasets\\Daphnet_Dataset\\dataset\"  # -----------\n",
    "args.freq_save_path = r\"D:\\TECO\\Paper\\Final_version\\Freq_data\"\n",
    "args.data_name = \"daphnet\"  # -----------\n",
    "\n",
    "args.difference = True \n",
    "\n",
    "args.sampling_freq =   64   # -----------\n",
    "args.windowsize = int(1 * args.sampling_freq) # -----------\n",
    "args.displacement =  int(0.5 * args.windowsize)  # -----------\n",
    "args.weighted  = False\n",
    "args.drop_long = False\n",
    "args.datanorm_type = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "args.wavename = \"morl\"\n",
    "\n",
    "# input information\n",
    "args.c_in      =  18 # it depends on the dataset # -----------\n",
    "args.input_length  =  args.windowsize\n",
    "args.num_classes  =  2 # -----------\n",
    "\n",
    "\n",
    "args.batch_size = 64\n",
    "args.shuffle = True\n",
    "args.drop_last = False\n",
    "args.train_vali_quote = 0.95\n",
    "\n",
    "\n",
    "\n",
    "args.exp_mode = \"Given\"\n",
    "args.model_type = \"time\"\n",
    "args.cls_token = True\n",
    "\n",
    "if args.model_type  in [\"time\",\"freq\",\"cross\"]:\n",
    "    args.light_weight      = False\n",
    "    # embedding \n",
    "    args.spectrogram      = True if args.model_type in [\"freq\",\"cross\"] else False\n",
    "    args.wavelet        = 'morl'\n",
    "\n",
    "    args.token_d_model     =  48\n",
    "    args.token_kernel_size   =  3\n",
    "    args.token_stride      =  1\n",
    "    args.token_conv_bias    =  True\n",
    "    args.token_activation    =  \"hardswish\"\n",
    "    args.token_norm       =  \"layer\"\n",
    "    args.token_n_layers     =  2\n",
    "    args.token_in_planes    =  48\n",
    "    args.token_max_pool     =  False\n",
    "    args.token_pool_kernel_size =  3\n",
    "    args.token_pool_stride    =  1\n",
    "    args.token_pool_pad      =  1\n",
    "    args.positional_embedding   = \"learnable\"    #None , \"learnable\" , \"sinus\"\n",
    "    args.input_embedding_dropout = 0.1\n",
    "\n",
    "    # Encoder\n",
    "    args.bias          = False\n",
    "    args.padding_mode      = \"replicate\"\n",
    "\n",
    "    args.single_depth        = 2\n",
    "    \n",
    "    # only model type == cross\n",
    "    args.cross_depth    = 1\n",
    "    args.t_depth        = 2\n",
    "    args.cross_atten_depth = 1\n",
    "    \n",
    "    args.distil         = False\n",
    "\n",
    "    #args.mask_flag                  = False\n",
    "    args.attention_layer_types = \"Full\" #[\"Full\",\"LocalSymmetry\",\"LocLogSymmetry\"]\n",
    "    args.attention_dropout   = 0.1   # attention map 也就是score的drop\n",
    "    args.output_attention    = True\n",
    "\n",
    "    args.n_heads        = 6\n",
    "    args.d_keys         = None\n",
    "    args.d_values        = None\n",
    "    args.causal_kernel_size   = 3\n",
    "    args.value_kernel_size   = 3\n",
    "    args.projection_dropout   = 0.1\n",
    "\n",
    "    args.feedforward_dim    = None\n",
    "    args.feedforward_dropout  = 0.1\n",
    "    args.feedforward_activation = \"hardswish\"\n",
    "    args.feedforward_norm_type = \"layer\"\n",
    "    args.forward_kernel_size  = 3\n",
    "    args.conv_activation    = \"hardswish\"\n",
    "    args.conv_norm       = \"layer\"\n",
    "else:\n",
    "    args.token_d_model     = 128\n",
    "    args.positional_embedding  = \"learnable\" # \"learnable\",\"fixed\"\n",
    "    args.input_embedding_dropout = 0.1\n",
    "    args.norm_type       = \"b\" # \"LayerNorm\" ,\"Batch\"\n",
    "    args.n_heads        = 8\n",
    "    args.dim_feedforward    = args.token_d_model*4\n",
    "    args.attn_dropout     = 0.1\n",
    "    args.activation      = \"relu\" # \"relu\", \"gelu\"\n",
    "    args.num_layers      = 4\n",
    "\n",
    "# training setting \n",
    "args.train_epochs       = 200\n",
    "\n",
    "args.learning_rate      = 0.001  \n",
    "args.learning_rate_patience  = 7\n",
    "args.learning_rate_factor   = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience    = 21\n",
    "\n",
    "args.use_gpu         = True if torch.cuda.is_available() else False\n",
    "args.gpu           = 0\n",
    "args.use_multi_gpu      = False\n",
    "\n",
    "args.optimizer        = \"Adam\"\n",
    "args.criterion        = \"CrossEntropy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49a53193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "beginn to build model\n",
      "build embedding Done\n",
      "build encoder Done\n",
      "build transformer Done\n",
      "build prediction Done\n",
      "Build the conv_TS model!\n",
      "Parameter : 124034\n",
      " ----------------------- load all the data -------------------\n",
      "----------------------- Get the Sliding Window -------------------\n",
      "The orginal class weights are :  [0.549 5.603]\n",
      "================ Given Mode ====================\n",
      "================ 1 CV ======================\n",
      "================ Build the model ================ \n",
      "beginn to build model\n",
      "build embedding Done\n",
      "build encoder Done\n",
      "build transformer Done\n",
      "build prediction Done\n",
      "Build the conv_TS model!\n",
      "================ the 1 th CV Experiment ================ \n",
      "After update the train test split , the class weight : [0.5472 5.7938]\n",
      "Train data number :  30545\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  18\n",
      "Test data number :  2754\n",
      "Epoch: 1 cost time: 21.129111528396606\n",
      "Epoch: 1, Steps: 478 | Train Loss: 0.2698735  Vali Loss: 0.4209782 Vali Accuracy: 0.8779956  Vali weighted F1: 0.8240122  Vali macro F1 0.4675174 \n",
      "Validation loss decreased (inf --> 0.420978).  Saving model ...\n",
      "Epoch: 2 cost time: 21.084667682647705\n",
      "Epoch: 2, Steps: 478 | Train Loss: 0.2487556  Vali Loss: 0.3380077 Vali Accuracy: 0.8812636  Vali weighted F1: 0.8256425  Vali macro F1 0.4684424 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.420978 --> 0.338008).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 21.064791202545166\n",
      "Epoch: 3, Steps: 478 | Train Loss: 0.2375310  Vali Loss: 0.3645568 Vali Accuracy: 0.8565723  Vali weighted F1: 0.8221370  Vali macro F1 0.5007414 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 4 cost time: 21.13386631011963\n",
      "Epoch: 4, Steps: 478 | Train Loss: 0.2310173  Vali Loss: 0.4248148 Vali Accuracy: 0.8416848  Vali weighted F1: 0.8241112  Vali macro F1 0.5402295 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 5 cost time: 21.11680269241333\n",
      "Epoch: 5, Steps: 478 | Train Loss: 0.2240734  Vali Loss: 0.4234562 Vali Accuracy: 0.8318809  Vali weighted F1: 0.8253759  Vali macro F1 0.5676312 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 6 cost time: 21.085362195968628\n",
      "Epoch: 6, Steps: 478 | Train Loss: 0.2186097  Vali Loss: 0.4328693 Vali Accuracy: 0.8787219  Vali weighted F1: 0.8296264  Vali macro F1 0.4904803 \n",
      "EarlyStopping counter: 4 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 7 cost time: 21.056747436523438\n",
      "Epoch: 7, Steps: 478 | Train Loss: 0.2127521  Vali Loss: 0.4487373 Vali Accuracy: 0.8307916  Vali weighted F1: 0.8141739  Vali macro F1 0.5184361 \n",
      "EarlyStopping counter: 5 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 8 cost time: 21.154008150100708\n",
      "Epoch: 8, Steps: 478 | Train Loss: 0.2078906  Vali Loss: 0.4054681 Vali Accuracy: 0.8631082  Vali weighted F1: 0.8238434  Vali macro F1 0.4953335 \n",
      "EarlyStopping counter: 6 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 9 cost time: 21.07169508934021\n",
      "Epoch: 9, Steps: 478 | Train Loss: 0.1997361  Vali Loss: 0.4430519 Vali Accuracy: 0.8416848  Vali weighted F1: 0.8292991  Vali macro F1 0.5638911 \n",
      "EarlyStopping counter: 7 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 10 cost time: 21.15282678604126\n",
      "Epoch: 10, Steps: 478 | Train Loss: 0.1766272  Vali Loss: 0.5167668 Vali Accuracy: 0.8380537  Vali weighted F1: 0.8193629  Vali macro F1 0.5264465 \n",
      "EarlyStopping counter: 8 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 11 cost time: 21.184775829315186\n",
      "Epoch: 11, Steps: 478 | Train Loss: 0.1689184  Vali Loss: 0.5380655 Vali Accuracy: 0.8228032  Vali weighted F1: 0.8146417  Vali macro F1 0.5382040 \n",
      "EarlyStopping counter: 9 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 12 cost time: 21.15060019493103\n",
      "Epoch: 12, Steps: 478 | Train Loss: 0.1630491  Vali Loss: 0.5835452 Vali Accuracy: 0.8202614  Vali weighted F1: 0.8130166  Vali macro F1 0.5363938 \n",
      "EarlyStopping counter: 10 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 13 cost time: 21.05203914642334\n",
      "Epoch: 13, Steps: 478 | Train Loss: 0.1603808  Vali Loss: 0.5721924 Vali Accuracy: 0.8082789  Vali weighted F1: 0.8085316  Vali macro F1 0.5431504 \n",
      "EarlyStopping counter: 11 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 14 cost time: 21.02174735069275\n",
      "Epoch: 14, Steps: 478 | Train Loss: 0.1574237  Vali Loss: 0.6214031 Vali Accuracy: 0.8315178  Vali weighted F1: 0.8183367  Vali macro F1 0.5358841 \n",
      "EarlyStopping counter: 12 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 15 cost time: 21.050745487213135\n",
      "Epoch: 15, Steps: 478 | Train Loss: 0.1554343  Vali Loss: 0.6351071 Vali Accuracy: 0.7912128  Vali weighted F1: 0.7955127  Vali macro F1 0.5218789 \n",
      "EarlyStopping counter: 13 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 16 cost time: 21.11604380607605\n",
      "Epoch: 16, Steps: 478 | Train Loss: 0.1523960  Vali Loss: 0.6800179 Vali Accuracy: 0.8053740  Vali weighted F1: 0.8012932  Vali macro F1 0.5156398 \n",
      "EarlyStopping counter: 14 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 17 cost time: 21.07121992111206\n",
      "Epoch: 17, Steps: 478 | Train Loss: 0.1472288  Vali Loss: 0.6755255 Vali Accuracy: 0.7999274  Vali weighted F1: 0.8000595  Vali macro F1 0.5226203 \n",
      "EarlyStopping counter: 15 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 18 cost time: 21.08075261116028\n",
      "Epoch: 18, Steps: 478 | Train Loss: 0.1471244  Vali Loss: 0.6793785 Vali Accuracy: 0.8013798  Vali weighted F1: 0.8017719  Vali macro F1 0.5273337 \n",
      "EarlyStopping counter: 16 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 19 cost time: 21.103936195373535\n",
      "Epoch: 19, Steps: 478 | Train Loss: 0.1464520  Vali Loss: 0.6851667 Vali Accuracy: 0.8010167  Vali weighted F1: 0.8010167  Vali macro F1 0.5245915 \n",
      "EarlyStopping counter: 17 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 20 cost time: 21.135958671569824\n",
      "Epoch: 20, Steps: 478 | Train Loss: 0.1443499  Vali Loss: 0.6889350 Vali Accuracy: 0.8071895  Vali weighted F1: 0.8049532  Vali macro F1 0.5286963 \n",
      "EarlyStopping counter: 18 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 21 cost time: 21.075645685195923\n",
      "Epoch: 21, Steps: 478 | Train Loss: 0.1449852  Vali Loss: 0.6941000 Vali Accuracy: 0.8021060  Vali weighted F1: 0.8022367  Vali macro F1 0.5278186 \n",
      "EarlyStopping counter: 19 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 22 cost time: 21.03475022315979\n",
      "Epoch: 22, Steps: 478 | Train Loss: 0.1436346  Vali Loss: 0.6945119 Vali Accuracy: 0.8046478  Vali weighted F1: 0.8025191  Vali macro F1 0.5231338 \n",
      "EarlyStopping counter: 20 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 23 cost time: 21.063748836517334\n",
      "Epoch: 23, Steps: 478 | Train Loss: 0.1443204  Vali Loss: 0.6989151 Vali Accuracy: 0.8035585  Vali weighted F1: 0.8026372  Vali macro F1 0.5262696 \n",
      "EarlyStopping counter: 21 out of 21\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "exp = Exp(args)\n",
    "exp.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62192d8e",
   "metadata": {},
   "source": [
    "# Skoda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fafa3823",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()    \n",
    "args.root_path =  r\"E:\\datasets\\Skoda HAR Dataset\"  # -----------\n",
    "args.freq_save_path = r\"G:\\Freq_data\"\n",
    "args.data_name = \"skodar\"  # -----------\n",
    "\n",
    "args.difference = True \n",
    "\n",
    "args.sampling_freq =   30   # -----------\n",
    "args.windowsize = int(2.56 * args.sampling_freq) # -----------\n",
    "args.displacement =  int(0.5 * args.windowsize)  # -----------\n",
    "args.weighted  = False\n",
    "args.drop_long = False\n",
    "args.datanorm_type = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "args.wavename = \"morl\"\n",
    "\n",
    "# input information\n",
    "args.c_in      =  60 # it depends on the dataset # -----------\n",
    "args.input_length  =  args.windowsize\n",
    "args.num_classes  =  10 # -----------\n",
    "\n",
    "args.batch_size = 128\n",
    "args.shuffle = True\n",
    "args.drop_last = False\n",
    "args.train_vali_quote = 0.95\n",
    "\n",
    "\n",
    "\n",
    "args.exp_mode = \"SOCV\"\n",
    "args.model_type = \"freq\"\n",
    "args.cls_token = True\n",
    "\n",
    "if args.model_type  in [\"time\",\"freq\",\"cross\"]:\n",
    "    args.light_weight      = False\n",
    "    # embedding \n",
    "    args.spectrogram      = True if args.model_type in [\"freq\",\"cross\"] else False\n",
    "    args.wavelet        = 'morl'\n",
    "\n",
    "    args.token_d_model     =  36\n",
    "    args.token_kernel_size   =  3\n",
    "    args.token_stride      =  1\n",
    "    args.token_conv_bias    =  True\n",
    "    args.token_activation    =  \"hardswish\"\n",
    "    args.token_norm       =  \"layer\"\n",
    "    args.token_n_layers     =  2\n",
    "    args.token_in_planes    =  36\n",
    "    args.token_max_pool     =  False\n",
    "    args.token_pool_kernel_size =  3\n",
    "    args.token_pool_stride    =  1\n",
    "    args.token_pool_pad      =  1\n",
    "    args.positional_embedding   = \"learnable\"    #None , \"learnable\" , \"sinus\"\n",
    "    args.input_embedding_dropout = 0.1\n",
    "\n",
    "    # Encoder\n",
    "    args.bias          = False\n",
    "    args.padding_mode      = \"replicate\"\n",
    "\n",
    "    args.single_depth        = 3\n",
    "    \n",
    "    # only model type == cross\n",
    "    args.cross_depth    = 1\n",
    "    args.t_depth        = 2\n",
    "    args.cross_atten_depth = 1\n",
    "    \n",
    "    args.distil         = False\n",
    "\n",
    "    #args.mask_flag                  = False\n",
    "    args.attention_layer_types = \"Full\" #[\"Full\",\"LocalSymmetry\",\"LocLogSymmetry\"]\n",
    "    args.attention_dropout   = 0.1   # attention map 也就是score的drop\n",
    "    args.output_attention    = True\n",
    "\n",
    "    args.n_heads        = 6\n",
    "    args.d_keys         = None\n",
    "    args.d_values        = None\n",
    "    args.causal_kernel_size   = 3\n",
    "    args.value_kernel_size   = 3\n",
    "    args.projection_dropout   = 0.1\n",
    "\n",
    "    args.feedforward_dim    = None\n",
    "    args.feedforward_dropout  = 0.1\n",
    "    args.feedforward_activation = \"hardswish\"\n",
    "    args.feedforward_norm_type = \"layer\"\n",
    "    args.forward_kernel_size  = 3\n",
    "    args.conv_activation    = \"hardswish\"\n",
    "    args.conv_norm       = \"layer\"\n",
    "else:\n",
    "    args.token_d_model     = 128\n",
    "    args.positional_embedding  = \"learnable\" # \"learnable\",\"fixed\"\n",
    "    args.input_embedding_dropout = 0.1\n",
    "    args.norm_type       = \"b\" # \"LayerNorm\" ,\"Batch\"\n",
    "    args.n_heads        = 8\n",
    "    args.dim_feedforward    = args.token_d_model*4\n",
    "    args.attn_dropout     = 0.1\n",
    "    args.activation      = \"relu\" # \"relu\", \"gelu\"\n",
    "    args.num_layers      = 4\n",
    "\n",
    "# training setting \n",
    "args.train_epochs       = 200\n",
    "\n",
    "args.learning_rate      = 0.001  \n",
    "args.learning_rate_patience  = 7\n",
    "args.learning_rate_factor   = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience    = 21\n",
    "\n",
    "args.use_gpu         = False # True if torch.cuda.is_available() else False\n",
    "args.gpu           = 0\n",
    "args.use_multi_gpu      = False\n",
    "\n",
    "args.optimizer        = \"Adam\"\n",
    "args.criterion        = \"CrossEntropy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63b6ae9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use CPU\n",
      "beginn to build model\n",
      "[60, 30, 1]\n",
      "channel , 30\n",
      "build embedding Done\n",
      "build encoder Done\n",
      "build transformer Done\n",
      "build prediction Done\n",
      "Build the conv_TS model!\n",
      "Parameter : 103273\n",
      " ----------------------- load all the data -------------------\n",
      "----------------------- Get the Sliding Window -------------------\n",
      "----------------------- spetrogram generating -----------------------\n",
      "================ SOCV Mode ====================\n",
      "================ 5 CV ======================\n",
      "================ Build the model ================ \n",
      "beginn to build model\n",
      "[60, 30, 1]\n",
      "channel , 30\n",
      "build embedding Done\n",
      "build encoder Done\n",
      "build transformer Done\n",
      "build prediction Done\n",
      "Build the conv_TS model!\n",
      "================ the 1 th CV Experiment ================ \n",
      "Overlapping random Experiment : The 0 Part as the test\n",
      "Train data number :  9979\n",
      "The number of classes is :  10\n",
      "The input_length  is :  76\n",
      "The channel_in is :  60\n",
      "Test data number :  2626\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4df318bc3032>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mexp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\TECO\\Paper\\Final_version\\git_conf_run_exp\\experiment.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    182\u001b[0m                     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m                     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m                     \u001b[0mmodel_optim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp = Exp(args)\n",
    "exp.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2a2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
