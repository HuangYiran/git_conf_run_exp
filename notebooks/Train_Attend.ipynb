{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4260c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "from dataloaders import data_set,data_dict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f56d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()    \n",
    "args.root_path =  r\"E:\\datasets\\UCI HAR Dataset\"                             # -----------\n",
    "args.freq_save_path = r\"D:\\TECO\\Paper\\Final_version\\Freq_data\"               # -----------\n",
    "args.to_save_path = r\"D:\\TECO\\Paper\\Final_version\\check\"                     # -----------\n",
    "args.data_name = \"ucihar\"                                                    # -----------\n",
    "\n",
    "args.difference = True \n",
    "\n",
    "args.sampling_freq =   50                                                    # -----------\n",
    "args.windowsize = int(2.56 * args.sampling_freq)                             # -----------\n",
    "args.displacement =  int(0.5 * args.windowsize)                                # -----------\n",
    "args.weighted  = False\n",
    "args.drop_long = False\n",
    "args.datanorm_type = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "args.wavename = \"morl\"\n",
    "\n",
    "# input information\n",
    "args.c_in      =  18 # it depends on the dataset                             # -----------\n",
    "args.input_length  =  args.windowsize                                        # -----------\n",
    "args.num_classes  =  6                                                      # -----------\n",
    "\n",
    "args.batch_size = 128                                                        # -----------\n",
    "args.shuffle = True\n",
    "args.drop_last = False\n",
    "args.train_vali_quote = 0.90                                               # -----------\n",
    "\n",
    "\n",
    "\n",
    "args.exp_mode = \"Given\"                                                      # -----------\n",
    "args.model_type = \"attend\"                                                  # -----------\n",
    "\n",
    "args.mixup = True  if    args.model_type == \"attend\" else False            # -----------\n",
    "args.alpha = 0.8 \n",
    "args.cls_token = True\n",
    "\n",
    "# training setting \n",
    "args.train_epochs       = 200\n",
    "\n",
    "args.learning_rate      = 0.0001  \n",
    "args.learning_rate_patience  = 4\n",
    "args.learning_rate_factor   = 0.5\n",
    "\n",
    "\n",
    "args.early_stop_patience    = 12\n",
    "\n",
    "args.use_gpu         = True if torch.cuda.is_available() else False\n",
    "args.gpu           = 0\n",
    "args.use_multi_gpu      = False\n",
    "\n",
    "args.optimizer        = \"Adam\"\n",
    "args.criterion        = \"CrossEntropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc3600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "Build the AttendDiscriminate model!\n",
      "Parameter : 666568\n",
      " ----------------------- load all the data -------------------\n",
      "----------------------- Get the Sliding Window -------------------\n",
      "================ Given Mode ====================\n",
      "================ 1 CV ======================\n",
      "================ Build the model ================ \n",
      " Using Mixup Training\n",
      "Build the AttendDiscriminate model!\n",
      "================ the 1 th CV Experiment ================ \n",
      "Train data number :  6616\n",
      "The number of classes is :  6\n",
      "The input_length  is :  128\n",
      "The channel_in is :  18\n",
      "Validation data number :  736\n",
      "Test data number :  2947\n",
      "Epoch: 1 cost time: 79.05281782150269\n",
      "VALI: Epoch: 1, Steps: 52 | Train Loss: 1.6537106  Vali Loss: 1.1041623 Vali Accuracy: 0.5244565  Vali weighted F1: 0.4039377  Vali macro F1 0.3984958 \n",
      "TEST: Epoch: 1, Steps: 52 | Train Loss: 1.6537106  Test Loss: 1.0926010 Test Accuracy: 0.5398711  Test weighted F1: 0.4406983  Test macro F1 0.4280407 \n",
      "Validation loss decreased (inf --> 1.104162).  Saving model ...\n",
      "Epoch: 2 cost time: 78.37607192993164\n",
      "VALI: Epoch: 2, Steps: 52 | Train Loss: 1.1510947  Vali Loss: 0.6316442 Vali Accuracy: 0.8532609  Vali weighted F1: 0.8516177  Vali macro F1 0.8496660 \n",
      "TEST: Epoch: 2, Steps: 52 | Train Loss: 1.1510947  Test Loss: 0.6478306 Test Accuracy: 0.8211741  Test weighted F1: 0.8211879  Test macro F1 0.8178281 \n",
      "new best score!!!!\n",
      "Validation loss decreased (1.104162 --> 0.631644).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 78.19077467918396\n",
      "VALI: Epoch: 3, Steps: 52 | Train Loss: 0.9939235  Vali Loss: 0.4577083 Vali Accuracy: 0.8858696  Vali weighted F1: 0.8852372  Vali macro F1 0.8879167 \n",
      "TEST: Epoch: 3, Steps: 52 | Train Loss: 0.9939235  Test Loss: 0.5005226 Test Accuracy: 0.8513743  Test weighted F1: 0.8522729  Test macro F1 0.8503065 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.631644 --> 0.457708).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 78.68828010559082\n",
      "VALI: Epoch: 4, Steps: 52 | Train Loss: 0.8772962  Vali Loss: 0.3458418 Vali Accuracy: 0.9008152  Vali weighted F1: 0.8997169  Vali macro F1 0.9067973 \n",
      "TEST: Epoch: 4, Steps: 52 | Train Loss: 0.8772962  Test Loss: 0.3972975 Test Accuracy: 0.8744486  Test weighted F1: 0.8749478  Test macro F1 0.8737900 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.457708 --> 0.345842).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 78.67905640602112\n",
      "VALI: Epoch: 5, Steps: 52 | Train Loss: 0.7907810  Vali Loss: 0.2854754 Vali Accuracy: 0.9157609  Vali weighted F1: 0.9148922  Vali macro F1 0.9247690 \n",
      "TEST: Epoch: 5, Steps: 52 | Train Loss: 0.7907810  Test Loss: 0.3360197 Test Accuracy: 0.8985409  Test weighted F1: 0.8985546  Test macro F1 0.8982145 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.345842 --> 0.285475).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 6 cost time: 79.14343500137329\n",
      "VALI: Epoch: 6, Steps: 52 | Train Loss: 0.7629601  Vali Loss: 0.2413306 Vali Accuracy: 0.9293478  Vali weighted F1: 0.9285215  Vali macro F1 0.9393763 \n",
      "TEST: Epoch: 6, Steps: 52 | Train Loss: 0.7629601  Test Loss: 0.3067157 Test Accuracy: 0.9053275  Test weighted F1: 0.9055141  Test macro F1 0.9051378 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.285475 --> 0.241331).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 7 cost time: 79.12321329116821\n",
      "VALI: Epoch: 7, Steps: 52 | Train Loss: 0.7249147  Vali Loss: 0.2188568 Vali Accuracy: 0.9334239  Vali weighted F1: 0.9329508  Vali macro F1 0.9439263 \n",
      "TEST: Epoch: 7, Steps: 52 | Train Loss: 0.7249147  Test Loss: 0.2817559 Test Accuracy: 0.9114354  Test weighted F1: 0.9114087  Test macro F1 0.9115330 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.241331 --> 0.218857).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 8 cost time: 78.37955665588379\n",
      "VALI: Epoch: 8, Steps: 52 | Train Loss: 0.7262198  Vali Loss: 0.2099753 Vali Accuracy: 0.9456522  Vali weighted F1: 0.9457173  Vali macro F1 0.9545069 \n",
      "TEST: Epoch: 8, Steps: 52 | Train Loss: 0.7262198  Test Loss: 0.2898302 Test Accuracy: 0.9107567  Test weighted F1: 0.9110038  Test macro F1 0.9109168 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.218857 --> 0.209975).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 79.1385018825531\n",
      "VALI: Epoch: 9, Steps: 52 | Train Loss: 0.7023664  Vali Loss: 0.2057577 Vali Accuracy: 0.9402174  Vali weighted F1: 0.9401870  Vali macro F1 0.9500869 \n",
      "TEST: Epoch: 9, Steps: 52 | Train Loss: 0.7023664  Test Loss: 0.2752392 Test Accuracy: 0.9138107  Test weighted F1: 0.9137430  Test macro F1 0.9137092 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.209975 --> 0.205758).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 10 cost time: 78.25813150405884\n",
      "VALI: Epoch: 10, Steps: 52 | Train Loss: 0.7039178  Vali Loss: 0.1942363 Vali Accuracy: 0.9442935  Vali weighted F1: 0.9442928  Vali macro F1 0.9536375 \n",
      "TEST: Epoch: 10, Steps: 52 | Train Loss: 0.7039178  Test Loss: 0.2626192 Test Accuracy: 0.9172039  Test weighted F1: 0.9172278  Test macro F1 0.9173358 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.205758 --> 0.194236).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 11 cost time: 78.1969723701477\n",
      "VALI: Epoch: 11, Steps: 52 | Train Loss: 0.6849709  Vali Loss: 0.1946431 Vali Accuracy: 0.9456522  Vali weighted F1: 0.9457200  Vali macro F1 0.9550450 \n",
      "TEST: Epoch: 11, Steps: 52 | Train Loss: 0.6849709  Test Loss: 0.2604442 Test Accuracy: 0.9226332  Test weighted F1: 0.9225703  Test macro F1 0.9231261 \n",
      "EarlyStopping counter: 1 out of 12\n",
      "Learning rate adjusting counter: 1 out of 4\n",
      "Epoch: 12 cost time: 78.33970332145691\n",
      "VALI: Epoch: 12, Steps: 52 | Train Loss: 0.6760569  Vali Loss: 0.1971969 Vali Accuracy: 0.9442935  Vali weighted F1: 0.9443592  Vali macro F1 0.9539509 \n",
      "TEST: Epoch: 12, Steps: 52 | Train Loss: 0.6760569  Test Loss: 0.2720329 Test Accuracy: 0.9222939  Test weighted F1: 0.9222383  Test macro F1 0.9226202 \n",
      "EarlyStopping counter: 2 out of 12\n",
      "Learning rate adjusting counter: 2 out of 4\n",
      "Epoch: 13 cost time: 78.28165531158447\n",
      "VALI: Epoch: 13, Steps: 52 | Train Loss: 0.6756094  Vali Loss: 0.1949345 Vali Accuracy: 0.9510870  Vali weighted F1: 0.9509132  Vali macro F1 0.9591509 \n",
      "TEST: Epoch: 13, Steps: 52 | Train Loss: 0.6756094  Test Loss: 0.2763355 Test Accuracy: 0.9202579  Test weighted F1: 0.9205191  Test macro F1 0.9209184 \n",
      "EarlyStopping counter: 3 out of 12\n",
      "Learning rate adjusting counter: 3 out of 4\n",
      "Epoch: 14 cost time: 78.33340764045715\n",
      "VALI: Epoch: 14, Steps: 52 | Train Loss: 0.6724708  Vali Loss: 0.1898717 Vali Accuracy: 0.9510870  Vali weighted F1: 0.9511370  Vali macro F1 0.9594926 \n",
      "TEST: Epoch: 14, Steps: 52 | Train Loss: 0.6724708  Test Loss: 0.2580959 Test Accuracy: 0.9209365  Test weighted F1: 0.9209597  Test macro F1 0.9214664 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.194236 --> 0.189872).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 15 cost time: 78.24770069122314\n",
      "VALI: Epoch: 15, Steps: 52 | Train Loss: 0.6639985  Vali Loss: 0.1844928 Vali Accuracy: 0.9551630  Vali weighted F1: 0.9551733  Vali macro F1 0.9627942 \n",
      "TEST: Epoch: 15, Steps: 52 | Train Loss: 0.6639985  Test Loss: 0.2546476 Test Accuracy: 0.9216152  Test weighted F1: 0.9215309  Test macro F1 0.9222984 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.189872 --> 0.184493).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 16 cost time: 78.30533075332642\n",
      "VALI: Epoch: 16, Steps: 52 | Train Loss: 0.6554588  Vali Loss: 0.1896524 Vali Accuracy: 0.9483696  Vali weighted F1: 0.9484306  Vali macro F1 0.9572694 \n",
      "TEST: Epoch: 16, Steps: 52 | Train Loss: 0.6554588  Test Loss: 0.2571716 Test Accuracy: 0.9212759  Test weighted F1: 0.9212493  Test macro F1 0.9216903 \n",
      "EarlyStopping counter: 1 out of 12\n",
      "Learning rate adjusting counter: 1 out of 4\n"
     ]
    }
   ],
   "source": [
    "exp = Exp(args)\n",
    "exp.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d993f79d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
